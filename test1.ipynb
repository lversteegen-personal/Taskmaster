{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run in colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/Github/Taskmaster\n",
    "#!pip install tensorflow --upgrade\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import small_rubiks as rubiks\n",
    "import numpy as np\n",
    "from student import student\n",
    "from classroom import classroom\n",
    "from teacher import teacher\n",
    "from small_rubiks_neural_networks import student_network\n",
    "from utils import dotdict\n",
    "from keras import regularizers\n",
    "\n",
    "task = rubiks.rubiks_task\n",
    "setup = rubiks.rubiks_setup\n",
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "#my_student_network = student_network.load(\"models/trained.h5\")\n",
    "params = dotdict({\n",
    "            \"residual_weights_reg\" : None,\n",
    "            \"residual_bias_reg\" : None,\n",
    "            \"relu_leak\" : 0.1,\n",
    "            \"residual_units\" : 300,\n",
    "            \"learning_rate\" : 0.001,\n",
    "            \"residual_layers\" : 4\n",
    "})\n",
    "my_student_network = student_network.create(params)\n",
    "student_template = student(task, 50,my_student_network)\n",
    "t = teacher(setup, lambda n : 1+rng.poisson(lam=3,size=n))\n",
    "c = classroom(task, setup, t, student_template, n_students=1, max_steps=10)\n",
    "#c.run_training_batch(n_problems=1,epochs_per_episode=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished step 0, 1 out of 1 remain open.\n",
      "Finished step 1, 1 out of 1 remain open.\n",
      "Finished step 2, 1 out of 1 remain open.\n",
      "Finished step 3, 1 out of 1 remain open.\n",
      "Finished step 4, 1 out of 1 remain open.\n",
      "Finished step 5, 1 out of 1 remain open.\n",
      "Finished step 6, 1 out of 1 remain open.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_problems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs_per_episode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#if i % 10 == 0:\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m#    my_student_network.save(\"models/t.keras\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\classroom.py:37\u001b[0m, in \u001b[0;36mclassroom.run_training_batch\u001b[1;34m(self, n_problems, epochs_per_episode)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_training_batch\u001b[39m(\u001b[39mself\u001b[39m, n_problems, epochs_per_episode):\n\u001b[0;32m     36\u001b[0m     problems \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mteacher\u001b[39m.\u001b[39mgenerate_problems(n_problems)\n\u001b[1;32m---> 37\u001b[0m     replay_record, proof_nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_students(problems)\n\u001b[0;32m     39\u001b[0m     replay_record\n\u001b[0;32m     41\u001b[0m     inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\classroom.py:76\u001b[0m, in \u001b[0;36mclassroom.test_students\u001b[1;34m(self, start_states)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_steps):\n\u001b[0;32m     75\u001b[0m     unfinished_task_indices \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i,p \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(task_nodes) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m p\u001b[39m.\u001b[39mcompleted]\n\u001b[1;32m---> 76\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstudent\u001b[39m.\u001b[39;49mrun_action_step([task_nodes[i] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m unfinished_task_indices])\n\u001b[0;32m     78\u001b[0m     \u001b[39mfor\u001b[39;00m j, (action, pi, eval_root) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(result):\n\u001b[0;32m     80\u001b[0m         k \u001b[39m=\u001b[39m unfinished_task_indices[j]\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:61\u001b[0m, in \u001b[0;36mstudent.run_action_step\u001b[1;34m(self, task_nodes)\u001b[0m\n\u001b[0;32m     57\u001b[0m eval_trees \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(initial_eval_trees)\n\u001b[0;32m     59\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_sim):\n\u001b[1;32m---> 61\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_simulation_step(eval_trees)\n\u001b[0;32m     62\u001b[0m     eval_trees\u001b[39m.\u001b[39mdifference_update([e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m eval_trees \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39mcompleted])\n\u001b[0;32m     64\u001b[0m result_list \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:37\u001b[0m, in \u001b[0;36mstudent.run_simulation_step\u001b[1;34m(self, eval_trees)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m eval_trees:\n\u001b[0;32m     35\u001b[0m     eval_leaves\u001b[39m.\u001b[39mappend(t\u001b[39m.\u001b[39mfind_leaf())\n\u001b[1;32m---> 37\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpand_task_nodes(eval_leaves)\n\u001b[0;32m     39\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(eval_trees):\n\u001b[0;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mcompleted:\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:23\u001b[0m, in \u001b[0;36mstudent.expand_task_nodes\u001b[1;34m(self, task_nodes)\u001b[0m\n\u001b[0;32m     20\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(task_nodes)\n\u001b[0;32m     21\u001b[0m task_nodes \u001b[39m=\u001b[39m [t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m s \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (t\u001b[39m.\u001b[39mcompleted \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mexpanded)]\n\u001b[1;32m---> 23\u001b[0m \u001b[39meval\u001b[39m,policy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mneural_network\u001b[39m.\u001b[39;49mpredict_value(task_nodes)\n\u001b[0;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(task_nodes):\n\u001b[0;32m     27\u001b[0m     t\u001b[39m.\u001b[39mexpand(\u001b[39meval\u001b[39m[i],policy[i])\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\small_rubiks_neural_networks.py:89\u001b[0m, in \u001b[0;36mstudent_network.predict_value\u001b[1;34m(self, task_nodes)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(task_nodes):\n\u001b[0;32m     87\u001b[0m     nn_input[i] \u001b[39m=\u001b[39m rubiks\u001b[39m.\u001b[39mmake_neural_input(t\u001b[39m.\u001b[39mstate)\n\u001b[1;32m---> 89\u001b[0m \u001b[39meval\u001b[39m, policy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue_network(nn_input)\n\u001b[0;32m     90\u001b[0m \u001b[39meval\u001b[39m, policy \u001b[39m=\u001b[39m (\u001b[39meval\u001b[39m\u001b[39m.\u001b[39mnumpy(),policy\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m     92\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39meval\u001b[39m, policy\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:590\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    588\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 590\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1148\u001b[0m ):\n\u001b[1;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py:515\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \n\u001b[0;32m    500\u001b[0m \u001b[39m    In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[39m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 515\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py:672\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    671\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 672\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mlayer(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    674\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[0;32m    676\u001b[0m     node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)\n\u001b[0;32m    677\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1148\u001b[0m ):\n\u001b[1;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:788\u001b[0m, in \u001b[0;36mBatchNormalizationBase.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[39mif\u001b[39;00m scale \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    787\u001b[0m     scale \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(scale, inputs\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m--> 788\u001b[0m outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mbatch_normalization(\n\u001b[0;32m    789\u001b[0m     inputs,\n\u001b[0;32m    790\u001b[0m     _broadcast(mean),\n\u001b[0;32m    791\u001b[0m     _broadcast(variance),\n\u001b[0;32m    792\u001b[0m     offset,\n\u001b[0;32m    793\u001b[0m     scale,\n\u001b[0;32m    794\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    795\u001b[0m )\n\u001b[0;32m    796\u001b[0m \u001b[39mif\u001b[39;00m inputs_dtype \u001b[39min\u001b[39;00m (tf\u001b[39m.\u001b[39mfloat16, tf\u001b[39m.\u001b[39mbfloat16):\n\u001b[0;32m    797\u001b[0m     outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(outputs, inputs_dtype)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:1482\u001b[0m, in \u001b[0;36mbatch_normalization\u001b[1;34m(x, mean, variance, offset, scale, variance_epsilon, name)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Batch normalization.\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m \n\u001b[0;32m   1431\u001b[0m \u001b[39mNormalizes a tensor by `mean` and `variance`, and applies (optionally) a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1479\u001b[0m \u001b[39m    ([pdf](http://proceedings.mlr.press/v37/ioffe15.pdf))\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(name, \u001b[39m\"\u001b[39m\u001b[39mbatchnorm\u001b[39m\u001b[39m\"\u001b[39m, [x, mean, variance, scale, offset]):\n\u001b[1;32m-> 1482\u001b[0m   inv \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39;49mrsqrt(variance \u001b[39m+\u001b[39;49m variance_epsilon)\n\u001b[0;32m   1483\u001b[0m   \u001b[39mif\u001b[39;00m scale \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1484\u001b[0m     inv \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m scale\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     87\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ops\u001b[39m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m op(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     89\u001b[0m   bound_arguments \u001b[39m=\u001b[39m signature\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m   bound_arguments\u001b[39m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\math_ops.py:5744\u001b[0m, in \u001b[0;36mrsqrt\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m   5722\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.rsqrt\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mmath.rsqrt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrsqrt\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   5723\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39mregister_unary_elementwise_api\n\u001b[0;32m   5724\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   5725\u001b[0m \u001b[39m@deprecation\u001b[39m\u001b[39m.\u001b[39mdeprecated_endpoints(\u001b[39m\"\u001b[39m\u001b[39mrsqrt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5726\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrsqrt\u001b[39m(x, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   5727\u001b[0m   \u001b[39m\"\"\"Computes reciprocal of square root of x element-wise.\u001b[39;00m\n\u001b[0;32m   5728\u001b[0m \n\u001b[0;32m   5729\u001b[0m \u001b[39m  For example:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5742\u001b[0m \u001b[39m    A `tf.Tensor`. Has the same type as `x`.\u001b[39;00m\n\u001b[0;32m   5743\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5744\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mrsqrt(x, name)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:8824\u001b[0m, in \u001b[0;36mrsqrt\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m   8822\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   8823\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 8824\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   8825\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mRsqrt\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, x)\n\u001b[0;32m   8826\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   8827\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    c.run_training_batch(n_problems=1,epochs_per_episode=3)\n",
    "    #if i % 10 == 0:\n",
    "    #    my_student_network.save(\"models/t.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "120/120 [==============================] - 3s 6ms/step - loss: 0.6253 - val_loss: 0.4650\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4461 - val_loss: 0.4431\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4259 - val_loss: 0.4346\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.4116 - val_loss: 0.4288\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4003 - val_loss: 0.4252\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3905 - val_loss: 0.4197\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3819 - val_loss: 0.4166\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3740 - val_loss: 0.4122\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3671 - val_loss: 0.4092\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3602 - val_loss: 0.4064\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3987 - val_loss: 0.4006\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3767 - val_loss: 0.3878\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3653 - val_loss: 0.3826\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3558 - val_loss: 0.3790\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3481 - val_loss: 0.3750\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3405 - val_loss: 0.3709\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3340 - val_loss: 0.3676\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3277 - val_loss: 0.3636\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3213 - val_loss: 0.3614\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3152 - val_loss: 0.3574\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3537 - val_loss: 0.3484\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3311 - val_loss: 0.3381\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3188 - val_loss: 0.3283\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3089 - val_loss: 0.3244\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3186\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2922 - val_loss: 0.3152\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2849 - val_loss: 0.3102\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2776 - val_loss: 0.3076\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2724 - val_loss: 0.3024\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2670 - val_loss: 0.3026\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3035 - val_loss: 0.2988\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2838 - val_loss: 0.2843\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2728 - val_loss: 0.2793\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2654 - val_loss: 0.2744\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2581 - val_loss: 0.2709\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2524 - val_loss: 0.2689\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2468 - val_loss: 0.2657\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2433 - val_loss: 0.2629\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2376 - val_loss: 0.2645\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2340 - val_loss: 0.2600\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2704 - val_loss: 0.2538\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2523 - val_loss: 0.2499\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2436 - val_loss: 0.2419\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2366 - val_loss: 0.2391\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2321 - val_loss: 0.2406\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2272 - val_loss: 0.2368\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2227 - val_loss: 0.2352\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2191 - val_loss: 0.2354\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2154 - val_loss: 0.2329\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2123 - val_loss: 0.2323\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2457 - val_loss: 0.2246\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2293 - val_loss: 0.2184\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2229 - val_loss: 0.2196\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2163 - val_loss: 0.2167\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2122 - val_loss: 0.2169\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2082 - val_loss: 0.2109\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2042 - val_loss: 0.2122\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2001 - val_loss: 0.2115\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1969 - val_loss: 0.2089\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1938 - val_loss: 0.2086\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2281 - val_loss: 0.2047\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2119 - val_loss: 0.2036\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2054 - val_loss: 0.1968\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1996 - val_loss: 0.1958\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1952 - val_loss: 0.1950\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1918 - val_loss: 0.1969\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1878 - val_loss: 0.1943\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1859 - val_loss: 0.1935\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1833 - val_loss: 0.1914\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1799 - val_loss: 0.1902\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.2110 - val_loss: 0.1862\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1961 - val_loss: 0.1815\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1890 - val_loss: 0.1780\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1841 - val_loss: 0.1823\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1798 - val_loss: 0.1815\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1769 - val_loss: 0.1759\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1739 - val_loss: 0.1745\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.1707 - val_loss: 0.1760\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 0.1686 - val_loss: 0.1720\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1669 - val_loss: 0.1735\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1971 - val_loss: 0.1683\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1840 - val_loss: 0.1649\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1774 - val_loss: 0.1648\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1719 - val_loss: 0.1620\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1680 - val_loss: 0.1624\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1650 - val_loss: 0.1597\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1624 - val_loss: 0.1616\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1595 - val_loss: 0.1603\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1573 - val_loss: 0.1593\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1552 - val_loss: 0.1574\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1834 - val_loss: 0.1547\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1693 - val_loss: 0.1497\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1633 - val_loss: 0.1519\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1598 - val_loss: 0.1460\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1566 - val_loss: 0.1447\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1528 - val_loss: 0.1475\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1507 - val_loss: 0.1438\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1484 - val_loss: 0.1421\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1467 - val_loss: 0.1414\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1458 - val_loss: 0.1426\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1712 - val_loss: 0.1440\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1597 - val_loss: 0.1392\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1537 - val_loss: 0.1387\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1487 - val_loss: 0.1370\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1460 - val_loss: 0.1376\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1436 - val_loss: 0.1380\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1406 - val_loss: 0.1333\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1400 - val_loss: 0.1346\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1372 - val_loss: 0.1326\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1346 - val_loss: 0.1340\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1626 - val_loss: 0.1285\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1503 - val_loss: 0.1285\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1435 - val_loss: 0.1210\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1407 - val_loss: 0.1252\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1372 - val_loss: 0.1205\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1350 - val_loss: 0.1190\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1326 - val_loss: 0.1198\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1313 - val_loss: 0.1201\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1288 - val_loss: 0.1190\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1282 - val_loss: 0.1152\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.1529 - val_loss: 0.1169\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1422 - val_loss: 0.1164\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1371 - val_loss: 0.1129\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1308 - val_loss: 0.1118\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1293 - val_loss: 0.1104\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1280 - val_loss: 0.1148\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1253 - val_loss: 0.1111\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1233 - val_loss: 0.1096\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1212 - val_loss: 0.1074\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.1203 - val_loss: 0.1158\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.1430 - val_loss: 0.1139\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1327 - val_loss: 0.1033\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1273 - val_loss: 0.1020\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1244 - val_loss: 0.1000\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1209 - val_loss: 0.1036\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1190 - val_loss: 0.0984\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1171 - val_loss: 0.0996\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.1153 - val_loss: 0.0989\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1141 - val_loss: 0.1005\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1129 - val_loss: 0.1021\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1373 - val_loss: 0.0959\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1263 - val_loss: 0.0915\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1206 - val_loss: 0.0898\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1185 - val_loss: 0.0931\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1179 - val_loss: 0.0919\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1128 - val_loss: 0.0910\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1122 - val_loss: 0.0892\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1103 - val_loss: 0.0894\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1083 - val_loss: 0.0886\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1079 - val_loss: 0.0907\n"
     ]
    }
   ],
   "source": [
    "from small_rubiks_neural_networks import student_network\n",
    "import numpy as np\n",
    "import small_rubiks as rubiks\n",
    "from utils import dotdict\n",
    "from keras import regularizers\n",
    "\n",
    "params = dotdict({\n",
    "    \"residual_weights_reg\" : regularizers.l2(0),\n",
    "    \"residual_bias_reg\" : regularizers.l2(0),\n",
    "    \"relu_leak\" : 0.1,\n",
    "    \"residual_units\" : 100,\n",
    "    \"learning_rate\" : 0.001,\n",
    "    \"residual_layers\" : 4\n",
    "})\n",
    "\n",
    "my_student_network = student_network()\n",
    "my_student_network.build_state_network(params)\n",
    "\n",
    "n=4096\n",
    "rng = np.random.default_rng(seed=0)\n",
    "states = np.arange(24)[None,:].repeat(n,axis=0)\n",
    "\n",
    "for k in range(15):\n",
    "    for i in range(30):\n",
    "        _, states = rubiks.task_action(states,rng.choice(a=12,size=n))\n",
    "\n",
    "    actions = rng.choice(12,size=n)\n",
    "    _, next_states = rubiks.task_action(states,actions)\n",
    "    my_student_network.fit_state(states,actions,next_states,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubiks.print_coloring(states[0])\n",
    "for i in range(12):\n",
    "    rubiks.print_coloring(rubiks.task_action(states[0],i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[9.9710751e-01, 6.0619249e-07, 1.4759846e-04, 8.7940595e-07,\n",
       "          2.7570887e-03, 9.7917059e-08],\n",
       "         [1.1799331e-05, 9.0194135e-06, 3.2481094e-04, 2.0508978e-06,\n",
       "          3.2106001e-08, 9.9986571e-01],\n",
       "         [1.8193028e-08, 1.8223140e-01, 2.0851733e-01, 7.3667913e-04,\n",
       "          4.2290463e-05, 7.5026892e-06],\n",
       "         [9.9984759e-01, 2.5260138e-07, 6.5540661e-07, 3.5026612e-06,\n",
       "          1.4787694e-03, 1.9846500e-06],\n",
       "         [5.9099410e-08, 2.3021027e-03, 5.8814701e-02, 2.1045190e-08,\n",
       "          3.1885473e-04, 2.2258115e-01],\n",
       "         [2.0254830e-04, 6.2786501e-07, 3.3112528e-07, 9.9999064e-01,\n",
       "          3.4769183e-09, 2.0986581e-03],\n",
       "         [1.0000000e+00, 2.5368703e-07, 2.5786532e-08, 2.0778268e-09,\n",
       "          7.2886853e-04, 5.1691532e-05],\n",
       "         [1.6136362e-07, 3.9164751e-04, 2.0268655e-07, 1.9103825e-06,\n",
       "          9.9992043e-01, 5.9300392e-06],\n",
       "         [5.3146548e-10, 1.0813341e-05, 1.0000000e+00, 1.7140443e-04,\n",
       "          7.0714083e-09, 2.1267698e-07],\n",
       "         [9.9999827e-01, 3.1747536e-06, 2.6413655e-08, 3.6168898e-05,\n",
       "          7.7556278e-06, 2.5332297e-06],\n",
       "         [1.6850383e-05, 3.4639870e-05, 5.0317613e-08, 2.7402384e-08,\n",
       "          1.0000000e+00, 2.6974307e-08],\n",
       "         [3.4419830e-07, 5.3591943e-08, 3.3830083e-04, 9.9999988e-01,\n",
       "          2.7375738e-12, 5.0315736e-03],\n",
       "         [7.9856845e-06, 9.9997711e-01, 2.9352856e-05, 5.2052241e-05,\n",
       "          1.4532069e-05, 1.4637417e-09],\n",
       "         [6.9797602e-06, 2.4171781e-05, 9.9999803e-01, 1.2007157e-09,\n",
       "          3.6655824e-06, 3.0137106e-05],\n",
       "         [1.4443050e-07, 1.8164987e-05, 3.3828765e-06, 3.5125723e-07,\n",
       "          1.0000000e+00, 1.8326841e-07],\n",
       "         [1.6329512e-06, 9.7506559e-01, 2.4227825e-06, 3.7015618e-06,\n",
       "          9.7841468e-05, 1.6358336e-04],\n",
       "         [1.7146807e-05, 1.2126694e-05, 9.9997455e-01, 2.1115027e-06,\n",
       "          1.1987912e-07, 6.3860614e-05],\n",
       "         [2.6049712e-03, 4.8565011e-07, 4.0692190e-04, 2.9961665e-08,\n",
       "          1.8460890e-08, 9.9999291e-01],\n",
       "         [1.5910342e-06, 9.9999529e-01, 4.1642934e-06, 2.2124664e-06,\n",
       "          6.6630508e-07, 2.8431670e-05],\n",
       "         [5.6720673e-06, 8.4679147e-07, 2.8689567e-04, 9.9972892e-01,\n",
       "          1.1080843e-07, 1.3738178e-05],\n",
       "         [5.9393798e-03, 5.8194671e-09, 1.8389835e-11, 2.9038197e-01,\n",
       "          9.9995548e-01, 2.6777911e-05],\n",
       "         [4.7860806e-07, 9.9994719e-01, 1.5825637e-05, 8.7591070e-05,\n",
       "          1.0238439e-06, 1.3295696e-05],\n",
       "         [1.4782695e-07, 1.7963712e-06, 1.7785203e-06, 9.9999988e-01,\n",
       "          4.8577243e-07, 1.4085504e-06],\n",
       "         [1.3268811e-02, 2.0712342e-07, 5.0071183e-08, 9.1192526e-08,\n",
       "          7.8381690e-06, 9.9999166e-01]]], dtype=float32),\n",
       " array([[0, 5, 2, 0, 5, 3, 0, 4, 2, 0, 4, 3, 1, 2, 4, 1, 2, 5, 1, 3, 4, 1,\n",
       "         3, 5]], dtype=int64),\n",
       " array([0, 5, 2, 0, 5, 3, 0, 4, 2, 0, 4, 3, 1, 2, 4, 1, 2, 5, 1, 3, 4, 1,\n",
       "        3, 5]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = np.arange(24)[None,:]\n",
    "actions = np.array([0])\n",
    "prediction = my_student_network.predict_state(states,actions)\n",
    "prediction.reshape(1,24,6), prediction.reshape(1,24,6).argmax(axis=2), rubiks.start_coloring[rubiks.task_action(states,actions)[1][0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea0df938a2fb4e996541c96a685bf803a61ab029232d990df5cc8c7e24c9f388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
