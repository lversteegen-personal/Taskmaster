{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run in colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/Github/Taskmaster\n",
    "#!pip install tensorflow --upgrade\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\leove\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\leove\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import rubiks as rubiks\n",
    "import numpy as np\n",
    "from student import student\n",
    "from classroom import classroom\n",
    "from teacher import teacher\n",
    "from general_task_network_experimental import student_network\n",
    "from utils import dotdict\n",
    "from keras import regularizers\n",
    "\n",
    "task = rubiks.rubiks_task\n",
    "setup = rubiks.rubiks_setup\n",
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "core_params = dotdict({\n",
    "            \"residual_weights_reg\" : None,\n",
    "            \"residual_bias_reg\" : None,\n",
    "            \"relu_leak\" : 0.05,\n",
    "            \"residual_units\" : 512,\n",
    "            \"learning_rate\" : 0.001,\n",
    "            \"residual_layers\" : 1\n",
    "})\n",
    "\n",
    "value_network_params = dotdict({\n",
    "            \"residual_weights_reg\" : None,\n",
    "            \"residual_bias_reg\" : None,\n",
    "            \"relu_leak\" : 0.05,\n",
    "            \"residual_units\" : 512,\n",
    "            \"learning_rate\" : 0.001,\n",
    "            \"post_core_residual_layers\" : 2,\n",
    "            \"reward_fork_layers\": 1,\n",
    "            \"value_fork_layers\": 1\n",
    "})\n",
    "\n",
    "state_network_params = dotdict({\n",
    "            \"residual_weights_reg\" : None,\n",
    "            \"residual_bias_reg\" : None,\n",
    "            \"relu_leak\" : 0.05,\n",
    "            \"residual_units\" : 300,\n",
    "            \"learning_rate\" : 0.001,\n",
    "            \"post_core_residual_layers\" : 2\n",
    "})\n",
    "\n",
    "params = dotdict({\n",
    "    \"core_params\":core_params,\n",
    "    \"value_network_params\": value_network_params,\n",
    "    \"state_network_params\": state_network_params,\n",
    "    \"state_size\":task.input_size,\n",
    "    \"action_codes\": task.n_actions\n",
    "})\n",
    "\n",
    "my_student_network = student_network.create(params)\n",
    "#my_student_network = student_network.load(\"models/combined/trained/trained\")\n",
    "student_template = student(task, 50,my_student_network,0.95)\n",
    "t = teacher(setup, lambda n : 1+rng.poisson(lam=3,size=n))\n",
    "c = classroom(task, setup, t, student_template, n_students=1, max_steps=10, buffer_size = lambda n : 2048)\n",
    "\n",
    "c.max_steps=5\n",
    "c.buffer_size = lambda n : np.minimum(4096,np.maximum(1024,n//2))\n",
    "t.step_dist = lambda n : 3*np.ones(n,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0.\n",
      "Before step 1, 98 out of 100 remain open.\n",
      "Before step 2, 92 out of 100 remain open.\n",
      "Before step 3, 85 out of 100 remain open.\n",
      "Before step 4, 83 out of 100 remain open.\n",
      "Before step 5, 83 out of 100 remain open.\n",
      "After step 5, 83 out of 100 remain open.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leove\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\leove\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "7/7 [==============================] - 5s 70ms/step - loss: 0.3652 - value_output_loss: 0.1092 - reward_output_loss: 0.1898 - reward_confidence_output_loss: 0.0662\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.3802 - value_output_loss: 0.0505 - reward_output_loss: 0.2579 - reward_confidence_output_loss: 0.0717\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 0s 67ms/step - loss: 0.3661 - value_output_loss: 0.0506 - reward_output_loss: 0.2479 - reward_confidence_output_loss: 0.0675\n",
      "Round 1.\n",
      "Before step 1, 99 out of 100 remain open.\n",
      "Before step 2, 96 out of 100 remain open.\n",
      "Before step 3, 96 out of 100 remain open.\n",
      "Before step 4, 95 out of 100 remain open.\n",
      "Before step 5, 93 out of 100 remain open.\n",
      "After step 5, 93 out of 100 remain open.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leove\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 12ms/step - loss: 0.2027 - value_output_loss: 0.0366 - reward_output_loss: 0.1188 - reward_confidence_output_loss: 0.0473\n",
      "Epoch 1/3\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.2001 - value_output_loss: 0.0366 - reward_output_loss: 0.1218 - reward_confidence_output_loss: 0.0417\n",
      "Epoch 2/3\n",
      "15/15 [==============================] - 1s 63ms/step - loss: 0.2042 - value_output_loss: 0.0367 - reward_output_loss: 0.1248 - reward_confidence_output_loss: 0.0428\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 1s 68ms/step - loss: 0.2078 - value_output_loss: 0.0367 - reward_output_loss: 0.1281 - reward_confidence_output_loss: 0.0431\n",
      "29/29 [==============================] - 1s 13ms/step\n",
      "29/29 [==============================] - 0s 16ms/step\n",
      "29/29 [==============================] - 1s 13ms/step\n",
      "Round 2.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 96 out of 100 remain open.\n",
      "Before step 3, 96 out of 100 remain open.\n",
      "Before step 4, 94 out of 100 remain open.\n",
      "Before step 5, 94 out of 100 remain open.\n",
      "After step 5, 92 out of 100 remain open.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leove\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0599 - value_output_loss: 0.0364 - reward_output_loss: 0.0161 - reward_confidence_output_loss: 0.0074\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0595 - value_output_loss: 0.0364 - reward_output_loss: 0.0161 - reward_confidence_output_loss: 0.0070\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.0595 - value_output_loss: 0.0364 - reward_output_loss: 0.0161 - reward_confidence_output_loss: 0.0070\n",
      "Round 3.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 81 out of 100 remain open.\n",
      "Before step 3, 81 out of 100 remain open.\n",
      "Before step 4, 81 out of 100 remain open.\n",
      "Before step 5, 80 out of 100 remain open.\n",
      "After step 5, 79 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.0484 - value_output_loss: 0.0451 - reward_output_loss: 0.0017 - reward_confidence_output_loss: 0.0017\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0484 - value_output_loss: 0.0451 - reward_output_loss: 0.0016 - reward_confidence_output_loss: 0.0016\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.0483 - value_output_loss: 0.0451 - reward_output_loss: 0.0016 - reward_confidence_output_loss: 0.0016\n",
      "Round 4.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 85 out of 100 remain open.\n",
      "Before step 3, 80 out of 100 remain open.\n",
      "Before step 4, 79 out of 100 remain open.\n",
      "Before step 5, 79 out of 100 remain open.\n",
      "After step 5, 79 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0592 - value_output_loss: 0.0550 - reward_output_loss: 0.0021 - reward_confidence_output_loss: 0.0021\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0592 - value_output_loss: 0.0550 - reward_output_loss: 0.0021 - reward_confidence_output_loss: 0.0021\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.0592 - value_output_loss: 0.0550 - reward_output_loss: 0.0021 - reward_confidence_output_loss: 0.0021\n",
      "Round 5.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 89 out of 100 remain open.\n",
      "Before step 3, 86 out of 100 remain open.\n",
      "Before step 4, 84 out of 100 remain open.\n",
      "Before step 5, 83 out of 100 remain open.\n",
      "After step 5, 83 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.0707 - value_output_loss: 0.0652 - reward_output_loss: 0.0028 - reward_confidence_output_loss: 0.0028\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0707 - value_output_loss: 0.0652 - reward_output_loss: 0.0028 - reward_confidence_output_loss: 0.0028\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0707 - value_output_loss: 0.0652 - reward_output_loss: 0.0028 - reward_confidence_output_loss: 0.0028\n",
      "Round 6.\n",
      "Before step 1, 98 out of 100 remain open.\n",
      "Before step 2, 84 out of 100 remain open.\n",
      "Before step 3, 80 out of 100 remain open.\n",
      "Before step 4, 79 out of 100 remain open.\n",
      "Before step 5, 78 out of 100 remain open.\n",
      "After step 5, 78 out of 100 remain open.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leove\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0731 - value_output_loss: 0.0675 - reward_output_loss: 0.0028 - reward_confidence_output_loss: 0.0028\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.0731 - value_output_loss: 0.0675 - reward_output_loss: 0.0028 - reward_confidence_output_loss: 0.0028\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0731 - value_output_loss: 0.0675 - reward_output_loss: 0.0028 - reward_confidence_output_loss: 0.0028\n",
      "Round 7.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 86 out of 100 remain open.\n",
      "Before step 3, 83 out of 100 remain open.\n",
      "Before step 4, 83 out of 100 remain open.\n",
      "Before step 5, 81 out of 100 remain open.\n",
      "After step 5, 80 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.0726 - value_output_loss: 0.0672 - reward_output_loss: 0.0027 - reward_confidence_output_loss: 0.0027\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0726 - value_output_loss: 0.0672 - reward_output_loss: 0.0027 - reward_confidence_output_loss: 0.0027\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.0726 - value_output_loss: 0.0672 - reward_output_loss: 0.0027 - reward_confidence_output_loss: 0.0027\n",
      "Round 8.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 88 out of 100 remain open.\n",
      "Before step 3, 84 out of 100 remain open.\n",
      "Before step 4, 82 out of 100 remain open.\n",
      "Before step 5, 81 out of 100 remain open.\n",
      "After step 5, 80 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 2s 129ms/step - loss: 0.0828 - value_output_loss: 0.0769 - reward_output_loss: 0.0029 - reward_confidence_output_loss: 0.0030\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0828 - value_output_loss: 0.0769 - reward_output_loss: 0.0029 - reward_confidence_output_loss: 0.0030\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.0828 - value_output_loss: 0.0769 - reward_output_loss: 0.0029 - reward_confidence_output_loss: 0.0030\n",
      "Round 9.\n",
      "Before step 1, 99 out of 100 remain open.\n",
      "Before step 2, 85 out of 100 remain open.\n",
      "Before step 3, 81 out of 100 remain open.\n",
      "Before step 4, 81 out of 100 remain open.\n",
      "Before step 5, 79 out of 100 remain open.\n",
      "After step 5, 79 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.0802 - value_output_loss: 0.0745 - reward_output_loss: 0.0029 - reward_confidence_output_loss: 0.0029\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0802 - value_output_loss: 0.0745 - reward_output_loss: 0.0029 - reward_confidence_output_loss: 0.0029\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0802 - value_output_loss: 0.0745 - reward_output_loss: 0.0029 - reward_confidence_output_loss: 0.0029\n",
      "Round 10.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 87 out of 100 remain open.\n",
      "Before step 3, 83 out of 100 remain open.\n",
      "Before step 4, 81 out of 100 remain open.\n",
      "Before step 5, 80 out of 100 remain open.\n",
      "After step 5, 78 out of 100 remain open.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leove\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0857 - value_output_loss: 0.0798 - reward_output_loss: 0.0030 - reward_confidence_output_loss: 0.0030\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0857 - value_output_loss: 0.0798 - reward_output_loss: 0.0030 - reward_confidence_output_loss: 0.0030\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.0857 - value_output_loss: 0.0798 - reward_output_loss: 0.0030 - reward_confidence_output_loss: 0.0030\n",
      "Round 11.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 87 out of 100 remain open.\n",
      "Before step 3, 84 out of 100 remain open.\n",
      "Before step 4, 83 out of 100 remain open.\n",
      "Before step 5, 82 out of 100 remain open.\n",
      "After step 5, 81 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0849 - value_output_loss: 0.0790 - reward_output_loss: 0.0030 - reward_confidence_output_loss: 0.0030\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0849 - value_output_loss: 0.0790 - reward_output_loss: 0.0030 - reward_confidence_output_loss: 0.0030\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.0849 - value_output_loss: 0.0790 - reward_output_loss: 0.0030 - reward_confidence_output_loss: 0.0030\n",
      "Round 12.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 86 out of 100 remain open.\n",
      "Before step 3, 80 out of 100 remain open.\n",
      "Before step 4, 77 out of 100 remain open.\n",
      "Before step 5, 77 out of 100 remain open.\n",
      "After step 5, 76 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0873 - value_output_loss: 0.0813 - reward_output_loss: 0.0030 - reward_confidence_output_loss: 0.0030\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0873 - value_output_loss: 0.0813 - reward_output_loss: 0.0030 - reward_confidence_output_loss: 0.0030\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0873 - value_output_loss: 0.0813 - reward_output_loss: 0.0030 - reward_confidence_output_loss: 0.0030\n",
      "Round 13.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 87 out of 100 remain open.\n",
      "Before step 3, 86 out of 100 remain open.\n",
      "Before step 4, 84 out of 100 remain open.\n",
      "Before step 5, 84 out of 100 remain open.\n",
      "After step 5, 84 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0751 - value_output_loss: 0.0694 - reward_output_loss: 0.0028 - reward_confidence_output_loss: 0.0028\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.5534 - value_output_loss: 0.5477 - reward_output_loss: 0.0028 - reward_confidence_output_loss: 0.0028\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0753 - value_output_loss: 0.0695 - reward_output_loss: 0.0028 - reward_confidence_output_loss: 0.0030\n",
      "Round 14.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 88 out of 100 remain open.\n",
      "Before step 3, 82 out of 100 remain open.\n",
      "Before step 4, 81 out of 100 remain open.\n",
      "Before step 5, 79 out of 100 remain open.\n",
      "After step 5, 78 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0811 - value_output_loss: 0.0754 - reward_output_loss: 0.0028 - reward_confidence_output_loss: 0.0028\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0811 - value_output_loss: 0.0754 - reward_output_loss: 0.0028 - reward_confidence_output_loss: 0.0028\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0811 - value_output_loss: 0.0754 - reward_output_loss: 0.0028 - reward_confidence_output_loss: 0.0028\n",
      "Round 15.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 88 out of 100 remain open.\n",
      "Before step 3, 83 out of 100 remain open.\n",
      "Before step 4, 82 out of 100 remain open.\n",
      "Before step 5, 82 out of 100 remain open.\n",
      "After step 5, 80 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0814 - value_output_loss: 0.0759 - reward_output_loss: 0.0028 - reward_confidence_output_loss: 0.0028\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0814 - value_output_loss: 0.0759 - reward_output_loss: 0.0028 - reward_confidence_output_loss: 0.0028\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0814 - value_output_loss: 0.0759 - reward_output_loss: 0.0028 - reward_confidence_output_loss: 0.0028\n",
      "Round 16.\n",
      "Before step 1, 99 out of 100 remain open.\n",
      "Before step 2, 89 out of 100 remain open.\n",
      "Before step 3, 86 out of 100 remain open.\n",
      "Before step 4, 84 out of 100 remain open.\n",
      "Before step 5, 84 out of 100 remain open.\n",
      "After step 5, 83 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0782 - value_output_loss: 0.0730 - reward_output_loss: 0.0026 - reward_confidence_output_loss: 0.0026\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0782 - value_output_loss: 0.0730 - reward_output_loss: 0.0026 - reward_confidence_output_loss: 0.0026\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0782 - value_output_loss: 0.0730 - reward_output_loss: 0.0026 - reward_confidence_output_loss: 0.0026\n",
      "Round 17.\n",
      "Before step 1, 99 out of 100 remain open.\n",
      "Before step 2, 86 out of 100 remain open.\n",
      "Before step 3, 85 out of 100 remain open.\n",
      "Before step 4, 85 out of 100 remain open.\n",
      "Before step 5, 83 out of 100 remain open.\n",
      "After step 5, 83 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0668 - value_output_loss: 0.0621 - reward_output_loss: 0.0023 - reward_confidence_output_loss: 0.0023\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.0668 - value_output_loss: 0.0621 - reward_output_loss: 0.0023 - reward_confidence_output_loss: 0.0023\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0668 - value_output_loss: 0.0621 - reward_output_loss: 0.0023 - reward_confidence_output_loss: 0.0023\n",
      "Round 18.\n",
      "Before step 1, 99 out of 100 remain open.\n",
      "3/3 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_problems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs_per_episode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m#if i % 10 == 9:\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m#    my_student_network.save(\"models/trained.h5\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\classroom.py:43\u001b[0m, in \u001b[0;36mclassroom.run_training_batch\u001b[1;34m(self, n_problems, epochs_per_episode)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_training_batch\u001b[39m(\u001b[39mself\u001b[39m, n_problems, epochs_per_episode):\n\u001b[0;32m     42\u001b[0m     problems \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mteacher\u001b[39m.\u001b[39mgenerate_problems(n_problems)\n\u001b[1;32m---> 43\u001b[0m     replay_record, proof_nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_students(problems)\n\u001b[0;32m     45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m n_problems\n\u001b[0;32m     46\u001b[0m     inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\classroom.py:110\u001b[0m, in \u001b[0;36mclassroom.test_students\u001b[1;34m(self, start_states)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBefore step \u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(unfinished_task_indices)\u001b[39m}\u001b[39;00m\u001b[39m out of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(task_nodes)\u001b[39m}\u001b[39;00m\u001b[39m remain open.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 110\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstudent\u001b[39m.\u001b[39;49mrun_action_step([task_nodes[i] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m unfinished_task_indices])\n\u001b[0;32m    112\u001b[0m \u001b[39mfor\u001b[39;00m j, (action, pi, eval_root) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(result):\n\u001b[0;32m    114\u001b[0m     k \u001b[39m=\u001b[39m unfinished_task_indices[j]\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:71\u001b[0m, in \u001b[0;36mstudent.run_action_step\u001b[1;34m(self, task_nodes)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_sim):\n\u001b[0;32m     70\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_simulation_step(eval_trees)\n\u001b[1;32m---> 71\u001b[0m     eval_trees\u001b[39m.\u001b[39mdifference_update([e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m eval_trees \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39mcompleted])\n\u001b[0;32m     73\u001b[0m result_list \u001b[39m=\u001b[39m []\n\u001b[0;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m i,t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(task_nodes):\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:71\u001b[0m, in \u001b[0;36mstudent.run_action_step\u001b[1;34m(self, task_nodes)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_sim):\n\u001b[0;32m     70\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_simulation_step(eval_trees)\n\u001b[1;32m---> 71\u001b[0m     eval_trees\u001b[39m.\u001b[39mdifference_update([e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m eval_trees \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39mcompleted])\n\u001b[0;32m     73\u001b[0m result_list \u001b[39m=\u001b[39m []\n\u001b[0;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m i,t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(task_nodes):\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1585\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\leove\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:1081\u001b[0m, in \u001b[0;36mPyDB.enable_tracing\u001b[1;34m(self, thread_trace_func, apply_to_all_threads)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe_eval_func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1080\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe_eval_func()\n\u001b[1;32m-> 1081\u001b[0m     pydevd_tracing\u001b[39m.\u001b[39;49mSetTrace(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdummy_trace_dispatch)\n\u001b[0;32m   1083\u001b[0m     \u001b[39mif\u001b[39;00m IS_CPYTHON \u001b[39mand\u001b[39;00m apply_to_all_threads:\n\u001b[0;32m   1084\u001b[0m         pydevd_tracing\u001b[39m.\u001b[39mset_trace_to_threads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdummy_trace_dispatch)\n",
      "File \u001b[1;32mc:\\Users\\leove\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_tracing.py:77\u001b[0m, in \u001b[0;36mSetTrace\u001b[1;34m(tracing_func)\u001b[0m\n\u001b[0;32m     74\u001b[0m _last_tracing_func_thread_local\u001b[39m.\u001b[39mtracing_func \u001b[39m=\u001b[39m tracing_func\n\u001b[0;32m     76\u001b[0m \u001b[39mif\u001b[39;00m tracing_func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 77\u001b[0m     \u001b[39mif\u001b[39;00m set_trace_to_threads(tracing_func, thread_idents\u001b[39m=\u001b[39;49m[thread\u001b[39m.\u001b[39;49mget_ident()], create_dummy_thread\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     78\u001b[0m         \u001b[39m# If we can use our own tracer instead of the one from sys.settrace, do it (the reason\u001b[39;00m\n\u001b[0;32m     79\u001b[0m         \u001b[39m# is that this is faster than the Python version because we don't call\u001b[39;00m\n\u001b[0;32m     80\u001b[0m         \u001b[39m# PyFrame_FastToLocalsWithError and PyFrame_LocalsToFast at each event!\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         \u001b[39m# (the difference can be huge when checking line events on frames as the\u001b[39;00m\n\u001b[0;32m     82\u001b[0m         \u001b[39m# time increases based on the number of local variables in the scope)\u001b[39;00m\n\u001b[0;32m     83\u001b[0m         \u001b[39m# See: InternalCallTrampoline (on the C side) for details.\u001b[39;00m\n\u001b[0;32m     84\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[39m# If it didn't work (or if it was None), use the Python version.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leove\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_tracing.py:345\u001b[0m, in \u001b[0;36mset_trace_to_threads\u001b[1;34m(tracing_func, thread_idents, create_dummy_thread)\u001b[0m\n\u001b[0;32m    343\u001b[0m start_new_thread \u001b[39m=\u001b[39m pydev_monkey\u001b[39m.\u001b[39mget_original_start_new_thread(thread)\n\u001b[0;32m    344\u001b[0m start_new_thread(increase_tracing_count, ())\n\u001b[1;32m--> 345\u001b[0m proceed\u001b[39m.\u001b[39;49macquire()  \u001b[39m# Only proceed after the release() is done.\u001b[39;00m\n\u001b[0;32m    346\u001b[0m proceed \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[39m# Note: The set_trace_func is not really used anymore in the C side.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(50):\n",
    "    print(f\"Round {i}.\")\n",
    "    c.run_training_batch(n_problems=100,epochs_per_episode=3)\n",
    "    #if i % 10 == 9:\n",
    "    #    my_student_network.save(\"models/trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0.\n",
      "Before step 1, 98 out of 100 remain open.\n",
      "Before step 2, 89 out of 100 remain open.\n",
      "Before step 3, 89 out of 100 remain open.\n",
      "Before step 4, 87 out of 100 remain open.\n",
      "Before step 5, 85 out of 100 remain open.\n",
      "After step 5, 85 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 9s 22ms/step - loss: 0.6726 - value_output_loss: 0.3565 - reward_output_loss: 0.1344 - reward_confidence_output_loss: 0.1817\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.5819 - value_output_loss: 0.3048 - reward_output_loss: 0.1163 - reward_confidence_output_loss: 0.1608\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4587 - value_output_loss: 0.2198 - reward_output_loss: 0.0989 - reward_confidence_output_loss: 0.1400\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 9s 23ms/step - loss: 0.5971 - val_loss: 0.4385\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4116 - val_loss: 0.4118\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3799 - val_loss: 0.4010\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3532 - val_loss: 0.3918\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3304 - val_loss: 0.3868\n",
      "Round 1.\n",
      "Before step 1, 99 out of 100 remain open.\n",
      "Before step 2, 96 out of 100 remain open.\n",
      "Before step 3, 96 out of 100 remain open.\n",
      "Before step 4, 96 out of 100 remain open.\n",
      "Before step 5, 96 out of 100 remain open.\n",
      "After step 5, 96 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "15/15 [==============================] - 7s 22ms/step - loss: 0.4057 - value_output_loss: 0.1331 - reward_output_loss: 0.1200 - reward_confidence_output_loss: 0.1526\n",
      "Epoch 2/3\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2533 - value_output_loss: 0.0832 - reward_output_loss: 0.0799 - reward_confidence_output_loss: 0.0902\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1658 - value_output_loss: 0.0530 - reward_output_loss: 0.0551 - reward_confidence_output_loss: 0.0578\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.3639 - val_loss: 0.3740\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.3238 - val_loss: 0.3486\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.3023 - val_loss: 0.3403\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.2856 - val_loss: 0.3400\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.2716 - val_loss: 0.3406\n",
      "Round 2.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 98 out of 100 remain open.\n",
      "Before step 3, 97 out of 100 remain open.\n",
      "Before step 4, 96 out of 100 remain open.\n",
      "Before step 5, 96 out of 100 remain open.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_problems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs_per_episode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m     10\u001b[0m         _, states \u001b[38;5;241m=\u001b[39m rubiks\u001b[38;5;241m.\u001b[39mtask_action(states,rng\u001b[38;5;241m.\u001b[39mchoice(a\u001b[38;5;241m=\u001b[39mtask\u001b[38;5;241m.\u001b[39mn_actions,size\u001b[38;5;241m=\u001b[39mn))\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\classroom.py:43\u001b[0m, in \u001b[0;36mclassroom.run_training_batch\u001b[1;34m(self, n_problems, epochs_per_episode)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_training_batch\u001b[39m(\u001b[39mself\u001b[39m, n_problems, epochs_per_episode):\n\u001b[0;32m     42\u001b[0m     problems \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mteacher\u001b[39m.\u001b[39mgenerate_problems(n_problems)\n\u001b[1;32m---> 43\u001b[0m     replay_record, proof_nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_students(problems)\n\u001b[0;32m     45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m n_problems\n\u001b[0;32m     46\u001b[0m     inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\classroom.py:108\u001b[0m, in \u001b[0;36mclassroom.test_students\u001b[1;34m(self, start_states)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBefore step \u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(unfinished_task_indices)\u001b[39m}\u001b[39;00m\u001b[39m out of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(task_nodes)\u001b[39m}\u001b[39;00m\u001b[39m remain open.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 108\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstudent\u001b[39m.\u001b[39;49mrun_action_step([task_nodes[i] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m unfinished_task_indices])\n\u001b[0;32m    110\u001b[0m \u001b[39mfor\u001b[39;00m j, (action, pi, eval_root) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(result):\n\u001b[0;32m    112\u001b[0m     k \u001b[39m=\u001b[39m unfinished_task_indices[j]\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:70\u001b[0m, in \u001b[0;36mstudent.run_action_step\u001b[1;34m(self, task_nodes)\u001b[0m\n\u001b[0;32m     66\u001b[0m eval_trees \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(initial_eval_trees)\n\u001b[0;32m     68\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_sim):\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_simulation_step(eval_trees)\n\u001b[0;32m     71\u001b[0m     eval_trees\u001b[39m.\u001b[39mdifference_update([e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m eval_trees \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39mcompleted])\n\u001b[0;32m     73\u001b[0m result_list \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:46\u001b[0m, in \u001b[0;36mstudent.run_simulation_step\u001b[1;34m(self, eval_trees)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m eval_trees:\n\u001b[0;32m     44\u001b[0m     eval_leaves\u001b[39m.\u001b[39mappend(t\u001b[39m.\u001b[39mfind_leaf())\n\u001b[1;32m---> 46\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpand_task_nodes(eval_leaves)\n\u001b[0;32m     48\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(eval_trees):\n\u001b[0;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mcompleted:\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:31\u001b[0m, in \u001b[0;36mstudent.expand_task_nodes\u001b[1;34m(self, task_nodes)\u001b[0m\n\u001b[0;32m     28\u001b[0m states \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([t\u001b[39m.\u001b[39mstate \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m task_nodes],dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[0;32m     29\u001b[0m state_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\u001b[39m.\u001b[39mmake_input(states)\n\u001b[1;32m---> 31\u001b[0m \u001b[39meval\u001b[39m,reward,reward_confidence \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mneural_network\u001b[39m.\u001b[39;49mpredict_value(state_input)\n\u001b[0;32m     33\u001b[0m t:task_tree_node\n\u001b[0;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(task_nodes):\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\general_task_network.py:147\u001b[0m, in \u001b[0;36mstudent_network.predict_value\u001b[1;34m(self, input_state)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_value\u001b[39m(\u001b[39mself\u001b[39m, input_state):\n\u001b[1;32m--> 147\u001b[0m     value, reward, reward_confidence \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue_network(input_state)\n\u001b[0;32m    148\u001b[0m     value, reward, reward_confidence \u001b[39m=\u001b[39m (value\u001b[39m.\u001b[39mnumpy(),reward\u001b[39m.\u001b[39mnumpy(),reward_confidence\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m    150\u001b[0m     \u001b[39mreturn\u001b[39;00m value, reward, reward_confidence\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:590\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    588\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 590\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1148\u001b[0m ):\n\u001b[1;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py:515\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \n\u001b[0;32m    500\u001b[0m \u001b[39m    In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[39m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 515\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py:672\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    671\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 672\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mlayer(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    674\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[0;32m    676\u001b[0m     node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)\n\u001b[0;32m    677\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1148\u001b[0m ):\n\u001b[1;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\activation.py:59\u001b[0m, in \u001b[0;36mActivation.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation(inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\activations.py:400\u001b[0m, in \u001b[0;36msigmoid\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkeras.activations.sigmoid\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    374\u001b[0m \u001b[39m@tf\u001b[39m\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m    375\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msigmoid\u001b[39m(x):\n\u001b[0;32m    376\u001b[0m     \u001b[39m\"\"\"Sigmoid activation function, `sigmoid(x) = 1 / (1 + exp(-x))`.\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \n\u001b[0;32m    378\u001b[0m \u001b[39m    Applies the sigmoid activation function. For small values (<-5),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39m        Tensor with the sigmoid activation: `1 / (1 + exp(-x))`.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49msigmoid(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:5915\u001b[0m, in \u001b[0;36msigmoid\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   5903\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkeras.backend.sigmoid\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5904\u001b[0m \u001b[39m@tf\u001b[39m\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   5905\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_generate_docs\n\u001b[0;32m   5906\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msigmoid\u001b[39m(x):\n\u001b[0;32m   5907\u001b[0m     \u001b[39m\"\"\"Element-wise sigmoid.\u001b[39;00m\n\u001b[0;32m   5908\u001b[0m \n\u001b[0;32m   5909\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5913\u001b[0m \u001b[39m        A tensor.\u001b[39;00m\n\u001b[0;32m   5914\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5915\u001b[0m     output \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49msigmoid(x)\n\u001b[0;32m   5916\u001b[0m     \u001b[39m# Cache the logits to use for crossentropy loss.\u001b[39;00m\n\u001b[0;32m   5917\u001b[0m     output\u001b[39m.\u001b[39m_keras_logits \u001b[39m=\u001b[39m x\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     87\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ops\u001b[39m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m op(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     89\u001b[0m   bound_arguments \u001b[39m=\u001b[39m signature\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m   bound_arguments\u001b[39m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\math_ops.py:4304\u001b[0m, in \u001b[0;36msigmoid\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m   4302\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(name, \u001b[39m\"\u001b[39m\u001b[39mSigmoid\u001b[39m\u001b[39m\"\u001b[39m, [x]) \u001b[39mas\u001b[39;00m name:\n\u001b[0;32m   4303\u001b[0m   x \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(x, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 4304\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49msigmoid(x, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:10130\u001b[0m, in \u001b[0;36msigmoid\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m  10128\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m  10129\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m> 10130\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m  10131\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mSigmoid\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, x)\n\u001b[0;32m  10132\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m  10133\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n=8192\n",
    "rng = np.random.default_rng(seed=0)\n",
    "states = np.arange(task.state_size)[None,:].repeat(n,axis=0)\n",
    "\n",
    "for k in range(20):\n",
    "    print(f\"Round {k}.\")\n",
    "    c.run_training_batch(n_problems=100,epochs_per_episode=3)\n",
    "\n",
    "    for i in range(50):\n",
    "        _, states = rubiks.task_action(states,rng.choice(a=task.n_actions,size=n))\n",
    "\n",
    "    actions = rng.choice(a=task.n_actions,size=n)\n",
    "    _, next_states = rubiks.task_action(states,actions)\n",
    "\n",
    "    actions = (np.arange(task.n_actions) == actions[...,None]).astype(float)\n",
    "    colors = rubiks.make_neural_input(states)\n",
    "    next_colors = rubiks.make_neural_input(next_states)\n",
    "    my_student_network.fit_state(colors,actions,next_colors,epochs = 5)\n",
    "\n",
    "    #if k % 10 == 9:\n",
    "    #  my_student_network.save(\"models/combined/trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 2, 4, 0, 2, 0, 2, 5, 4, 1, 4, 4, 1, 0, 3, 4, 0, 3, 0, 3, 5, 2,\n",
       "         4, 2, 2, 5, 1, 0, 3, 4, 3, 3, 5, 1, 2, 4, 1, 2, 1, 2, 5, 5, 1, 5,\n",
       "         5, 0, 1, 3, 4, 1, 3, 1, 3, 5]], dtype=int64),\n",
       " array([0, 2, 4, 0, 2, 0, 2, 5, 4, 1, 4, 4, 0, 0, 3, 4, 0, 3, 0, 3, 5, 2,\n",
       "        4, 2, 2, 5, 1, 0, 3, 4, 3, 3, 5, 1, 2, 4, 1, 2, 1, 2, 5, 5, 1, 5,\n",
       "        5, 0, 1, 3, 4, 1, 3, 1, 3, 5]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states =  np.arange(54,dtype=int)[None,:]\n",
    "actions = np.array([9],dtype=int)\n",
    "prediction = my_student_network.predict_state(task.make_input(states),(np.arange(task.n_actions) == actions[...,None]).astype(float))\n",
    "prediction.reshape(1,54,6).argmax(axis=2), rubiks.start_coloring[rubiks.task_action(states,actions)[1][0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea0df938a2fb4e996541c96a685bf803a61ab029232d990df5cc8c7e24c9f388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
