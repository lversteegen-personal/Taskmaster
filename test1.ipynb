{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run in colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/Github/Taskmaster\n",
    "#!pip install tensorflow --upgrade\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import small_rubiks as rubiks\n",
    "import numpy as np\n",
    "from student import student\n",
    "from classroom import classroom\n",
    "from teacher import teacher\n",
    "from small_rubiks_neural_networks import student_network\n",
    "from utils import dotdict\n",
    "from keras import regularizers\n",
    "\n",
    "task = rubiks.rubiks_task\n",
    "setup = rubiks.rubiks_setup\n",
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "params = dotdict({\n",
    "            \"residual_weights_reg\" : None,\n",
    "            \"residual_bias_reg\" : None,\n",
    "            \"relu_leak\" : 0.1,\n",
    "            \"residual_units\" : 200,\n",
    "            \"learning_rate\" : 0.001,\n",
    "            \"residual_layers\" : 3\n",
    "})\n",
    "my_student_network = student_network.create(params)\n",
    "#my_student_network = student_network.load_value_network(\"models/trained.h5\")\n",
    "student_template = student(task, 50,my_student_network)\n",
    "t = teacher(setup, lambda n : 1+rng.poisson(lam=3,size=n))#np.ones(n,dtype=int)\n",
    "c = classroom(task, setup, t, student_template, n_students=1, max_steps=10, buffer_size = lambda n : 2048)\n",
    "#c.run_training_batch(n_problems=1,epochs_per_episode=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished step 0, 100 out of 100 remain open.\n",
      "Finished step 1, 93 out of 100 remain open.\n",
      "Finished step 2, 93 out of 100 remain open.\n",
      "Finished step 3, 71 out of 100 remain open.\n",
      "Finished step 4, 71 out of 100 remain open.\n",
      "Finished step 5, 71 out of 100 remain open.\n",
      "Finished step 6, 71 out of 100 remain open.\n",
      "Finished step 7, 71 out of 100 remain open.\n",
      "Finished step 8, 71 out of 100 remain open.\n",
      "Finished step 9, 71 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\leove\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\leove\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "25/25 [==============================] - 6s 7ms/step - loss: 0.5220 - eval_output_loss: 0.1706 - policy_output_loss: 0.0928 - policy_confidence_output_loss: 0.2586\n",
      "Epoch 2/3\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.2933 - eval_output_loss: 0.0942 - policy_output_loss: 0.0493 - policy_confidence_output_loss: 0.1498\n",
      "Epoch 3/3\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.1884 - eval_output_loss: 0.0782 - policy_output_loss: 0.0309 - policy_confidence_output_loss: 0.0793\n",
      "Finished step 0, 100 out of 100 remain open.\n",
      "Finished step 1, 12 out of 100 remain open.\n",
      "Finished step 2, 12 out of 100 remain open.\n",
      "Finished step 3, 0 out of 100 remain open.\n",
      "Finished step 4, 0 out of 100 remain open.\n",
      "Finished step 5, 0 out of 100 remain open.\n",
      "Finished step 6, 0 out of 100 remain open.\n",
      "Finished step 7, 0 out of 100 remain open.\n",
      "Finished step 8, 0 out of 100 remain open.\n",
      "Finished step 9, 0 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1960 - eval_output_loss: 0.1147 - policy_output_loss: 0.0280 - policy_confidence_output_loss: 0.0533\n",
      "Epoch 2/3\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1531 - eval_output_loss: 0.0943 - policy_output_loss: 0.0240 - policy_confidence_output_loss: 0.0348\n",
      "Epoch 3/3\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.1224 - eval_output_loss: 0.0769 - policy_output_loss: 0.0215 - policy_confidence_output_loss: 0.0241\n",
      "Finished step 0, 100 out of 100 remain open.\n",
      "Finished step 1, 10 out of 100 remain open.\n",
      "Finished step 2, 10 out of 100 remain open.\n",
      "Finished step 3, 0 out of 100 remain open.\n",
      "Finished step 4, 0 out of 100 remain open.\n",
      "Finished step 5, 0 out of 100 remain open.\n",
      "Finished step 6, 0 out of 100 remain open.\n",
      "Finished step 7, 0 out of 100 remain open.\n",
      "Finished step 8, 0 out of 100 remain open.\n",
      "Finished step 9, 0 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.1597 - eval_output_loss: 0.1077 - policy_output_loss: 0.0209 - policy_confidence_output_loss: 0.0311\n",
      "Epoch 2/3\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.1626 - eval_output_loss: 0.1135 - policy_output_loss: 0.0204 - policy_confidence_output_loss: 0.0286\n",
      "Epoch 3/3\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.1469 - eval_output_loss: 0.0991 - policy_output_loss: 0.0198 - policy_confidence_output_loss: 0.0280\n",
      "Finished step 0, 100 out of 100 remain open.\n",
      "Finished step 1, 9 out of 100 remain open.\n",
      "Finished step 2, 9 out of 100 remain open.\n",
      "Finished step 3, 0 out of 100 remain open.\n",
      "Finished step 4, 0 out of 100 remain open.\n",
      "Finished step 5, 0 out of 100 remain open.\n",
      "Finished step 6, 0 out of 100 remain open.\n",
      "Finished step 7, 0 out of 100 remain open.\n",
      "Finished step 8, 0 out of 100 remain open.\n",
      "Finished step 9, 0 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1741 - eval_output_loss: 0.1163 - policy_output_loss: 0.0227 - policy_confidence_output_loss: 0.0351\n",
      "Epoch 2/3\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1657 - eval_output_loss: 0.1153 - policy_output_loss: 0.0177 - policy_confidence_output_loss: 0.0327\n",
      "Epoch 3/3\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1568 - eval_output_loss: 0.1074 - policy_output_loss: 0.0170 - policy_confidence_output_loss: 0.0324\n",
      "Finished step 0, 100 out of 100 remain open.\n",
      "Finished step 1, 18 out of 100 remain open.\n",
      "Finished step 2, 18 out of 100 remain open.\n",
      "Finished step 3, 0 out of 100 remain open.\n",
      "Finished step 4, 0 out of 100 remain open.\n",
      "Finished step 5, 0 out of 100 remain open.\n",
      "Finished step 6, 0 out of 100 remain open.\n",
      "Finished step 7, 0 out of 100 remain open.\n",
      "Finished step 8, 0 out of 100 remain open.\n",
      "Finished step 9, 0 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.1602 - eval_output_loss: 0.1080 - policy_output_loss: 0.0167 - policy_confidence_output_loss: 0.0356\n",
      "Epoch 2/3\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1575 - eval_output_loss: 0.1078 - policy_output_loss: 0.0153 - policy_confidence_output_loss: 0.0345\n",
      "Epoch 3/3\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.1549 - eval_output_loss: 0.1067 - policy_output_loss: 0.0149 - policy_confidence_output_loss: 0.0333\n",
      "Finished step 0, 100 out of 100 remain open.\n",
      "Finished step 1, 20 out of 100 remain open.\n",
      "Finished step 2, 20 out of 100 remain open.\n",
      "Finished step 3, 0 out of 100 remain open.\n",
      "Finished step 4, 0 out of 100 remain open.\n",
      "Finished step 5, 0 out of 100 remain open.\n",
      "Finished step 6, 0 out of 100 remain open.\n",
      "Finished step 7, 0 out of 100 remain open.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_problems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs_per_episode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#if i % 10 == 0:\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m#    my_student_network.save(\"models/trained.h5\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\classroom.py:43\u001b[0m, in \u001b[0;36mclassroom.run_training_batch\u001b[1;34m(self, n_problems, epochs_per_episode)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_training_batch\u001b[39m(\u001b[39mself\u001b[39m, n_problems, epochs_per_episode):\n\u001b[0;32m     42\u001b[0m     problems \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mteacher\u001b[39m.\u001b[39mgenerate_problems(n_problems)\n\u001b[1;32m---> 43\u001b[0m     replay_record, proof_nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_students(problems)\n\u001b[0;32m     45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m n_problems\n\u001b[0;32m     46\u001b[0m     inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\classroom.py:98\u001b[0m, in \u001b[0;36mclassroom.test_students\u001b[1;34m(self, start_states)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_steps):\n\u001b[0;32m     97\u001b[0m     unfinished_task_indices \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i,p \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(task_nodes) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m p\u001b[39m.\u001b[39mcompleted]\n\u001b[1;32m---> 98\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstudent\u001b[39m.\u001b[39;49mrun_action_step([task_nodes[i] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m unfinished_task_indices])\n\u001b[0;32m    100\u001b[0m     \u001b[39mfor\u001b[39;00m j, (action, pi, eval_root) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(result):\n\u001b[0;32m    102\u001b[0m         k \u001b[39m=\u001b[39m unfinished_task_indices[j]\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:62\u001b[0m, in \u001b[0;36mstudent.run_action_step\u001b[1;34m(self, task_nodes)\u001b[0m\n\u001b[0;32m     58\u001b[0m eval_trees \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(initial_eval_trees)\n\u001b[0;32m     60\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_sim):\n\u001b[1;32m---> 62\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_simulation_step(eval_trees)\n\u001b[0;32m     63\u001b[0m     eval_trees\u001b[39m.\u001b[39mdifference_update([e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m eval_trees \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39mcompleted])\n\u001b[0;32m     65\u001b[0m result_list \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:38\u001b[0m, in \u001b[0;36mstudent.run_simulation_step\u001b[1;34m(self, eval_trees)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m eval_trees:\n\u001b[0;32m     36\u001b[0m     eval_leaves\u001b[39m.\u001b[39mappend(t\u001b[39m.\u001b[39mfind_leaf())\n\u001b[1;32m---> 38\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpand_task_nodes(eval_leaves)\n\u001b[0;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(eval_trees):\n\u001b[0;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mcompleted:\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:23\u001b[0m, in \u001b[0;36mstudent.expand_task_nodes\u001b[1;34m(self, task_nodes)\u001b[0m\n\u001b[0;32m     20\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(task_nodes)\n\u001b[0;32m     21\u001b[0m task_nodes \u001b[39m=\u001b[39m [t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m s \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (t\u001b[39m.\u001b[39mcompleted \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mexpanded)]\n\u001b[1;32m---> 23\u001b[0m \u001b[39meval\u001b[39m,policy,policy_confidence \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mneural_network\u001b[39m.\u001b[39;49mpredict_value(task_nodes)\n\u001b[0;32m     25\u001b[0m t:task_tree_node\n\u001b[0;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(task_nodes):\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\small_rubiks_neural_networks.py:92\u001b[0m, in \u001b[0;36mstudent_network.predict_value\u001b[1;34m(self, task_nodes)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(task_nodes):\n\u001b[0;32m     90\u001b[0m     nn_input[i] \u001b[39m=\u001b[39m rubiks\u001b[39m.\u001b[39mmake_neural_input(t\u001b[39m.\u001b[39mstate)\n\u001b[1;32m---> 92\u001b[0m value, policy, policy_confidence \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue_network(nn_input)\n\u001b[0;32m     93\u001b[0m value, policy, policy_confidence \u001b[39m=\u001b[39m (value\u001b[39m.\u001b[39mnumpy(),policy\u001b[39m.\u001b[39mnumpy(),policy_confidence\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m     95\u001b[0m \u001b[39mreturn\u001b[39;00m value, policy, policy_confidence\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:590\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    588\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 590\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1148\u001b[0m ):\n\u001b[1;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py:515\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \n\u001b[0;32m    500\u001b[0m \u001b[39m    In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[39m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 515\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py:672\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    671\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 672\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mlayer(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    674\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[0;32m    676\u001b[0m     node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)\n\u001b[0;32m    677\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1148\u001b[0m ):\n\u001b[1;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:241\u001b[0m, in \u001b[0;36mDense.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    237\u001b[0m         outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39membedding_lookup_sparse(\n\u001b[0;32m    238\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel, ids, weights, combiner\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msum\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m         )\n\u001b[0;32m    240\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 241\u001b[0m         outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mmatmul(a\u001b[39m=\u001b[39;49minputs, b\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel)\n\u001b[0;32m    242\u001b[0m \u001b[39m# Broadcast kernel to inputs.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mtensordot(inputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel, [[rank \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m], [\u001b[39m0\u001b[39m]])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    141\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ops\u001b[39m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m op(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m   bound_arguments \u001b[39m=\u001b[39m signature\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    144\u001b[0m   bound_arguments\u001b[39m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3842\u001b[0m, in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[0;32m   3839\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39mbatch_mat_mul_v3(\n\u001b[0;32m   3840\u001b[0m       a, b, adj_x\u001b[39m=\u001b[39madjoint_a, adj_y\u001b[39m=\u001b[39madjoint_b, Tout\u001b[39m=\u001b[39moutput_type, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m   3841\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3842\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mmat_mul(\n\u001b[0;32m   3843\u001b[0m       a, b, transpose_a\u001b[39m=\u001b[39;49mtranspose_a, transpose_b\u001b[39m=\u001b[39;49mtranspose_b, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6171\u001b[0m, in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6169\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   6170\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 6171\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   6172\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMatMul\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, a, b, \u001b[39m\"\u001b[39;49m\u001b[39mtranspose_a\u001b[39;49m\u001b[39m\"\u001b[39;49m, transpose_a, \u001b[39m\"\u001b[39;49m\u001b[39mtranspose_b\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   6173\u001b[0m       transpose_b)\n\u001b[0;32m   6174\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   6175\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    c.run_training_batch(n_problems=100,epochs_per_episode=3)\n",
    "    #if i % 10 == 0:\n",
    "    #    my_student_network.save(\"models/trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "120/120 [==============================] - 3s 6ms/step - loss: 0.6253 - val_loss: 0.4650\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4461 - val_loss: 0.4431\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4259 - val_loss: 0.4346\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.4116 - val_loss: 0.4288\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4003 - val_loss: 0.4252\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3905 - val_loss: 0.4197\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3819 - val_loss: 0.4166\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3740 - val_loss: 0.4122\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3671 - val_loss: 0.4092\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3602 - val_loss: 0.4064\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3987 - val_loss: 0.4006\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3767 - val_loss: 0.3878\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3653 - val_loss: 0.3826\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3558 - val_loss: 0.3790\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3481 - val_loss: 0.3750\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3405 - val_loss: 0.3709\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3340 - val_loss: 0.3676\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3277 - val_loss: 0.3636\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3213 - val_loss: 0.3614\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3152 - val_loss: 0.3574\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3537 - val_loss: 0.3484\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3311 - val_loss: 0.3381\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3188 - val_loss: 0.3283\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3089 - val_loss: 0.3244\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3186\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2922 - val_loss: 0.3152\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2849 - val_loss: 0.3102\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2776 - val_loss: 0.3076\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2724 - val_loss: 0.3024\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2670 - val_loss: 0.3026\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3035 - val_loss: 0.2988\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2838 - val_loss: 0.2843\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2728 - val_loss: 0.2793\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2654 - val_loss: 0.2744\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2581 - val_loss: 0.2709\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2524 - val_loss: 0.2689\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2468 - val_loss: 0.2657\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2433 - val_loss: 0.2629\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2376 - val_loss: 0.2645\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2340 - val_loss: 0.2600\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2704 - val_loss: 0.2538\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2523 - val_loss: 0.2499\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2436 - val_loss: 0.2419\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2366 - val_loss: 0.2391\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2321 - val_loss: 0.2406\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2272 - val_loss: 0.2368\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2227 - val_loss: 0.2352\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2191 - val_loss: 0.2354\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2154 - val_loss: 0.2329\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2123 - val_loss: 0.2323\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2457 - val_loss: 0.2246\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2293 - val_loss: 0.2184\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2229 - val_loss: 0.2196\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2163 - val_loss: 0.2167\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2122 - val_loss: 0.2169\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2082 - val_loss: 0.2109\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2042 - val_loss: 0.2122\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2001 - val_loss: 0.2115\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1969 - val_loss: 0.2089\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1938 - val_loss: 0.2086\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2281 - val_loss: 0.2047\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2119 - val_loss: 0.2036\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2054 - val_loss: 0.1968\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1996 - val_loss: 0.1958\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1952 - val_loss: 0.1950\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1918 - val_loss: 0.1969\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1878 - val_loss: 0.1943\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1859 - val_loss: 0.1935\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1833 - val_loss: 0.1914\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1799 - val_loss: 0.1902\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.2110 - val_loss: 0.1862\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1961 - val_loss: 0.1815\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1890 - val_loss: 0.1780\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1841 - val_loss: 0.1823\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1798 - val_loss: 0.1815\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1769 - val_loss: 0.1759\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1739 - val_loss: 0.1745\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.1707 - val_loss: 0.1760\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 0.1686 - val_loss: 0.1720\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1669 - val_loss: 0.1735\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1971 - val_loss: 0.1683\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1840 - val_loss: 0.1649\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1774 - val_loss: 0.1648\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1719 - val_loss: 0.1620\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1680 - val_loss: 0.1624\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1650 - val_loss: 0.1597\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1624 - val_loss: 0.1616\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1595 - val_loss: 0.1603\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1573 - val_loss: 0.1593\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1552 - val_loss: 0.1574\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1834 - val_loss: 0.1547\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1693 - val_loss: 0.1497\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1633 - val_loss: 0.1519\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1598 - val_loss: 0.1460\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1566 - val_loss: 0.1447\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1528 - val_loss: 0.1475\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1507 - val_loss: 0.1438\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1484 - val_loss: 0.1421\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1467 - val_loss: 0.1414\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1458 - val_loss: 0.1426\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1712 - val_loss: 0.1440\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1597 - val_loss: 0.1392\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1537 - val_loss: 0.1387\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1487 - val_loss: 0.1370\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1460 - val_loss: 0.1376\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1436 - val_loss: 0.1380\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1406 - val_loss: 0.1333\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1400 - val_loss: 0.1346\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1372 - val_loss: 0.1326\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1346 - val_loss: 0.1340\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1626 - val_loss: 0.1285\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1503 - val_loss: 0.1285\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1435 - val_loss: 0.1210\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1407 - val_loss: 0.1252\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1372 - val_loss: 0.1205\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1350 - val_loss: 0.1190\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1326 - val_loss: 0.1198\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1313 - val_loss: 0.1201\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1288 - val_loss: 0.1190\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1282 - val_loss: 0.1152\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.1529 - val_loss: 0.1169\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1422 - val_loss: 0.1164\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1371 - val_loss: 0.1129\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1308 - val_loss: 0.1118\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1293 - val_loss: 0.1104\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1280 - val_loss: 0.1148\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1253 - val_loss: 0.1111\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1233 - val_loss: 0.1096\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1212 - val_loss: 0.1074\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.1203 - val_loss: 0.1158\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.1430 - val_loss: 0.1139\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1327 - val_loss: 0.1033\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1273 - val_loss: 0.1020\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1244 - val_loss: 0.1000\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1209 - val_loss: 0.1036\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1190 - val_loss: 0.0984\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1171 - val_loss: 0.0996\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.1153 - val_loss: 0.0989\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1141 - val_loss: 0.1005\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1129 - val_loss: 0.1021\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1373 - val_loss: 0.0959\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1263 - val_loss: 0.0915\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1206 - val_loss: 0.0898\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1185 - val_loss: 0.0931\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1179 - val_loss: 0.0919\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1128 - val_loss: 0.0910\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1122 - val_loss: 0.0892\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1103 - val_loss: 0.0894\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1083 - val_loss: 0.0886\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1079 - val_loss: 0.0907\n"
     ]
    }
   ],
   "source": [
    "from small_rubiks_neural_networks import student_network\n",
    "import numpy as np\n",
    "import small_rubiks as rubiks\n",
    "from utils import dotdict\n",
    "from keras import regularizers\n",
    "\n",
    "params = dotdict({\n",
    "    \"residual_weights_reg\" : regularizers.l2(0),\n",
    "    \"residual_bias_reg\" : regularizers.l2(0),\n",
    "    \"relu_leak\" : 0.1,\n",
    "    \"residual_units\" : 100,\n",
    "    \"learning_rate\" : 0.001,\n",
    "    \"residual_layers\" : 4\n",
    "})\n",
    "\n",
    "my_student_network = student_network()\n",
    "my_student_network.build_state_network(params)\n",
    "\n",
    "n=4096\n",
    "rng = np.random.default_rng(seed=0)\n",
    "states = np.arange(24)[None,:].repeat(n,axis=0)\n",
    "\n",
    "for k in range(15):\n",
    "    for i in range(30):\n",
    "        _, states = rubiks.task_action(states,rng.choice(a=12,size=n))\n",
    "\n",
    "    actions = rng.choice(12,size=n)\n",
    "    _, next_states = rubiks.task_action(states,actions)\n",
    "    my_student_network.fit_state(states,actions,next_states,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.arange(24)[None,:]\n",
    "actions = np.array([0])\n",
    "prediction = my_student_network.predict_state(states,actions)\n",
    "prediction.reshape(1,24,6), prediction.reshape(1,24,6).argmax(axis=2), rubiks.start_coloring[rubiks.task_action(states,actions)[1][0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea0df938a2fb4e996541c96a685bf803a61ab029232d990df5cc8c7e24c9f388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
