{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run in colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/Github/Taskmaster\n",
    "#!pip install tensorflow --upgrade\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubiks as rubiks\n",
    "import numpy as np\n",
    "from student import student\n",
    "from classroom import classroom\n",
    "from teacher import teacher\n",
    "from general_task_network import student_network\n",
    "from utils import dotdict\n",
    "from keras import regularizers\n",
    "\n",
    "task = rubiks.rubiks_task\n",
    "setup = rubiks.rubiks_setup\n",
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "core_params = dotdict({\n",
    "            \"residual_weights_reg\" : None,\n",
    "            \"residual_bias_reg\" : None,\n",
    "            \"relu_leak\" : 0.05,\n",
    "            \"residual_units\" : 300,\n",
    "            \"learning_rate\" : 0.001,\n",
    "            \"residual_layers\" : 3\n",
    "})\n",
    "\n",
    "value_network_params = dotdict({\n",
    "            \"residual_weights_reg\" : None,\n",
    "            \"residual_bias_reg\" : None,\n",
    "            \"relu_leak\" : 0.05,\n",
    "            \"residual_units\" : 300,\n",
    "            \"learning_rate\" : 0.001,\n",
    "            \"post_core_residual_layers\" : 2,\n",
    "            \"reward_fork_layers\": 1,\n",
    "            \"value_fork_layers\": 1\n",
    "})\n",
    "\n",
    "state_network_params = dotdict({\n",
    "            \"residual_weights_reg\" : None,\n",
    "            \"residual_bias_reg\" : None,\n",
    "            \"relu_leak\" : 0.05,\n",
    "            \"residual_units\" : 300,\n",
    "            \"learning_rate\" : 0.001,\n",
    "            \"post_core_residual_layers\" : 2\n",
    "})\n",
    "\n",
    "params = dotdict({\n",
    "    \"core_params\":core_params,\n",
    "    \"value_network_params\": value_network_params,\n",
    "    \"state_network_params\": state_network_params,\n",
    "    \"state_size\":task.state_size,\n",
    "    \"action_codes\": task.n_actions\n",
    "})\n",
    "\n",
    "my_student_network = student_network.create(params)\n",
    "#my_student_network = student_network.load(\"models/combined/trained/trained\")\n",
    "student_template = student(task, 50,my_student_network,0.95)\n",
    "t = teacher(setup, lambda n : 1+rng.poisson(lam=3,size=n))\n",
    "c = classroom(task, setup, t, student_template, n_students=1, max_steps=10, buffer_size = lambda n : 2048)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.max_steps=5\n",
    "c.buffer_size = lambda n : 8192\n",
    "t.step_dist = lambda n : 3*np.ones(n,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(10):\n",
    "    print(f\"Round {i}.\")\n",
    "    c.run_training_batch(n_problems=100,epochs_per_episode=3)\n",
    "    #if i % 10 == 9:\n",
    "    #    my_student_network.save(\"models/trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 87 out of 100 remain open.\n",
      "Before step 3, 79 out of 100 remain open.\n",
      "Before step 4, 47 out of 100 remain open.\n",
      "Before step 5, 40 out of 100 remain open.\n",
      "After step 5, 38 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 0.0576 - value_output_loss: 0.0444 - reward_output_loss: 0.0063 - reward_confidence_output_loss: 0.0069\n",
      "Epoch 2/3\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.0495 - value_output_loss: 0.0368 - reward_output_loss: 0.0061 - reward_confidence_output_loss: 0.0065\n",
      "Epoch 3/3\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.0434 - value_output_loss: 0.0318 - reward_output_loss: 0.0056 - reward_confidence_output_loss: 0.0060\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.2698 - val_loss: 0.2620\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.2496 - val_loss: 0.2575\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.2410 - val_loss: 0.2575\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.2337 - val_loss: 0.2581\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.2269 - val_loss: 0.2594\n",
      "Round 1.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 84 out of 100 remain open.\n",
      "Before step 3, 72 out of 100 remain open.\n",
      "Before step 4, 40 out of 100 remain open.\n",
      "Before step 5, 37 out of 100 remain open.\n",
      "After step 5, 36 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "43/43 [==============================] - 1s 22ms/step - loss: 0.0714 - value_output_loss: 0.0522 - reward_output_loss: 0.0095 - reward_confidence_output_loss: 0.0098\n",
      "Epoch 2/3\n",
      "43/43 [==============================] - 1s 23ms/step - loss: 0.0540 - value_output_loss: 0.0371 - reward_output_loss: 0.0083 - reward_confidence_output_loss: 0.0086\n",
      "Epoch 3/3\n",
      "43/43 [==============================] - 1s 23ms/step - loss: 0.0488 - value_output_loss: 0.0322 - reward_output_loss: 0.0082 - reward_confidence_output_loss: 0.0085\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.2626 - val_loss: 0.2679\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2418 - val_loss: 0.2612\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2337 - val_loss: 0.2622\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2267 - val_loss: 0.2627\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2205 - val_loss: 0.2647\n",
      "Round 2.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 94 out of 100 remain open.\n",
      "Before step 3, 89 out of 100 remain open.\n",
      "Before step 4, 51 out of 100 remain open.\n",
      "Before step 5, 44 out of 100 remain open.\n",
      "After step 5, 42 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.0771 - value_output_loss: 0.0552 - reward_output_loss: 0.0108 - reward_confidence_output_loss: 0.0111\n",
      "Epoch 2/3\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.0618 - value_output_loss: 0.0414 - reward_output_loss: 0.0100 - reward_confidence_output_loss: 0.0103\n",
      "Epoch 3/3\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.0519 - value_output_loss: 0.0335 - reward_output_loss: 0.0090 - reward_confidence_output_loss: 0.0093\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.2562 - val_loss: 0.2532\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2356 - val_loss: 0.2469\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2271 - val_loss: 0.2453\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2209 - val_loss: 0.2461\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2147 - val_loss: 0.2474\n",
      "Round 3.\n",
      "Before step 1, 99 out of 100 remain open.\n",
      "Before step 2, 87 out of 100 remain open.\n",
      "Before step 3, 78 out of 100 remain open.\n",
      "Before step 4, 57 out of 100 remain open.\n",
      "Before step 5, 49 out of 100 remain open.\n",
      "After step 5, 49 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "55/55 [==============================] - 1s 22ms/step - loss: 0.0728 - value_output_loss: 0.0505 - reward_output_loss: 0.0110 - reward_confidence_output_loss: 0.0113\n",
      "Epoch 2/3\n",
      "55/55 [==============================] - 1s 23ms/step - loss: 0.0607 - value_output_loss: 0.0389 - reward_output_loss: 0.0108 - reward_confidence_output_loss: 0.0110\n",
      "Epoch 3/3\n",
      "55/55 [==============================] - 1s 23ms/step - loss: 0.0536 - value_output_loss: 0.0333 - reward_output_loss: 0.0101 - reward_confidence_output_loss: 0.0102\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.2486 - val_loss: 0.2429\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2284 - val_loss: 0.2356\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2205 - val_loss: 0.2347\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2143 - val_loss: 0.2347\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2088 - val_loss: 0.2359\n",
      "Round 4.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 87 out of 100 remain open.\n",
      "Before step 3, 79 out of 100 remain open.\n",
      "Before step 4, 48 out of 100 remain open.\n",
      "Before step 5, 44 out of 100 remain open.\n",
      "After step 5, 43 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.0703 - value_output_loss: 0.0476 - reward_output_loss: 0.0112 - reward_confidence_output_loss: 0.0115\n",
      "Epoch 2/3\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.0615 - value_output_loss: 0.0399 - reward_output_loss: 0.0107 - reward_confidence_output_loss: 0.0109\n",
      "Epoch 3/3\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.0525 - value_output_loss: 0.0325 - reward_output_loss: 0.0099 - reward_confidence_output_loss: 0.0101\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.2394 - val_loss: 0.2352\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2203 - val_loss: 0.2301\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2127 - val_loss: 0.2296\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2070 - val_loss: 0.2304\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2020 - val_loss: 0.2320\n",
      "Round 5.\n",
      "Before step 1, 98 out of 100 remain open.\n",
      "Before step 2, 84 out of 100 remain open.\n",
      "Before step 3, 74 out of 100 remain open.\n",
      "Before step 4, 39 out of 100 remain open.\n",
      "Before step 5, 37 out of 100 remain open.\n",
      "After step 5, 35 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.0690 - value_output_loss: 0.0458 - reward_output_loss: 0.0116 - reward_confidence_output_loss: 0.0117\n",
      "Epoch 2/3\n",
      "66/66 [==============================] - 1s 23ms/step - loss: 0.0656 - value_output_loss: 0.0425 - reward_output_loss: 0.0114 - reward_confidence_output_loss: 0.0116\n",
      "Epoch 3/3\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.0607 - value_output_loss: 0.0386 - reward_output_loss: 0.0110 - reward_confidence_output_loss: 0.0111\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2321 - val_loss: 0.2281\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2136 - val_loss: 0.2235\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.2064 - val_loss: 0.2243\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2009 - val_loss: 0.2235\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1957 - val_loss: 0.2260\n",
      "Round 6.\n",
      "Before step 1, 98 out of 100 remain open.\n",
      "Before step 2, 87 out of 100 remain open.\n",
      "Before step 3, 79 out of 100 remain open.\n",
      "Before step 4, 44 out of 100 remain open.\n",
      "Before step 5, 41 out of 100 remain open.\n",
      "After step 5, 37 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "71/71 [==============================] - 2s 23ms/step - loss: 0.0712 - value_output_loss: 0.0468 - reward_output_loss: 0.0122 - reward_confidence_output_loss: 0.0122\n",
      "Epoch 2/3\n",
      "71/71 [==============================] - 2s 23ms/step - loss: 0.0604 - value_output_loss: 0.0369 - reward_output_loss: 0.0117 - reward_confidence_output_loss: 0.0118\n",
      "Epoch 3/3\n",
      "71/71 [==============================] - 2s 23ms/step - loss: 0.0567 - value_output_loss: 0.0345 - reward_output_loss: 0.0111 - reward_confidence_output_loss: 0.0111\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2250 - val_loss: 0.2198\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2065 - val_loss: 0.2150\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1988 - val_loss: 0.2141\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1931 - val_loss: 0.2136\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1870 - val_loss: 0.2145\n",
      "Round 7.\n",
      "Before step 1, 99 out of 100 remain open.\n",
      "Before step 2, 80 out of 100 remain open.\n",
      "Before step 3, 72 out of 100 remain open.\n",
      "Before step 4, 48 out of 100 remain open.\n",
      "Before step 5, 39 out of 100 remain open.\n",
      "After step 5, 34 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "76/76 [==============================] - 2s 23ms/step - loss: 0.0649 - value_output_loss: 0.0406 - reward_output_loss: 0.0121 - reward_confidence_output_loss: 0.0121\n",
      "Epoch 2/3\n",
      "76/76 [==============================] - 2s 23ms/step - loss: 0.0616 - value_output_loss: 0.0385 - reward_output_loss: 0.0115 - reward_confidence_output_loss: 0.0116\n",
      "Epoch 3/3\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.0528 - value_output_loss: 0.0309 - reward_output_loss: 0.0109 - reward_confidence_output_loss: 0.0110\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.2169 - val_loss: 0.2128\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1978 - val_loss: 0.2090\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.1888 - val_loss: 0.2075\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1823 - val_loss: 0.2077\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1765 - val_loss: 0.2082\n",
      "Round 8.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 89 out of 100 remain open.\n",
      "Before step 3, 80 out of 100 remain open.\n",
      "Before step 4, 43 out of 100 remain open.\n",
      "Before step 5, 38 out of 100 remain open.\n",
      "After step 5, 37 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 0.0675 - value_output_loss: 0.0427 - reward_output_loss: 0.0124 - reward_confidence_output_loss: 0.0124\n",
      "Epoch 2/3\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 0.0619 - value_output_loss: 0.0385 - reward_output_loss: 0.0117 - reward_confidence_output_loss: 0.0117\n",
      "Epoch 3/3\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 0.0575 - value_output_loss: 0.0344 - reward_output_loss: 0.0115 - reward_confidence_output_loss: 0.0115\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.2100 - val_loss: 0.1995\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1889 - val_loss: 0.1927\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.1794 - val_loss: 0.1913\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1724 - val_loss: 0.1915\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1656 - val_loss: 0.1894\n",
      "Round 9.\n",
      "Before step 1, 99 out of 100 remain open.\n",
      "Before step 2, 90 out of 100 remain open.\n",
      "Before step 3, 82 out of 100 remain open.\n",
      "Before step 4, 42 out of 100 remain open.\n",
      "Before step 5, 36 out of 100 remain open.\n",
      "After step 5, 33 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "87/87 [==============================] - 2s 23ms/step - loss: 0.0675 - value_output_loss: 0.0421 - reward_output_loss: 0.0127 - reward_confidence_output_loss: 0.0127\n",
      "Epoch 2/3\n",
      "87/87 [==============================] - 2s 23ms/step - loss: 0.0627 - value_output_loss: 0.0388 - reward_output_loss: 0.0120 - reward_confidence_output_loss: 0.0120\n",
      "Epoch 3/3\n",
      "87/87 [==============================] - 2s 22ms/step - loss: 0.0549 - value_output_loss: 0.0318 - reward_output_loss: 0.0115 - reward_confidence_output_loss: 0.0116\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.1960 - val_loss: 0.1865\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1743 - val_loss: 0.1803\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1644 - val_loss: 0.1781\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1571 - val_loss: 0.1761\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1503 - val_loss: 0.1758\n",
      "Round 10.\n",
      "Before step 1, 99 out of 100 remain open.\n",
      "Before step 2, 85 out of 100 remain open.\n",
      "Before step 3, 72 out of 100 remain open.\n",
      "Before step 4, 31 out of 100 remain open.\n",
      "Before step 5, 27 out of 100 remain open.\n",
      "After step 5, 26 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0611 - value_output_loss: 0.0376 - reward_output_loss: 0.0117 - reward_confidence_output_loss: 0.0118\n",
      "Epoch 2/3\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.0594 - value_output_loss: 0.0362 - reward_output_loss: 0.0115 - reward_confidence_output_loss: 0.0116\n",
      "Epoch 3/3\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.0546 - value_output_loss: 0.0322 - reward_output_loss: 0.0112 - reward_confidence_output_loss: 0.0112\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.1812 - val_loss: 0.1691\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.1603 - val_loss: 0.1644\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1505 - val_loss: 0.1601\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.1432 - val_loss: 0.1598\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1375 - val_loss: 0.1603\n",
      "Round 11.\n",
      "Before step 1, 98 out of 100 remain open.\n",
      "Before step 2, 89 out of 100 remain open.\n",
      "Before step 3, 80 out of 100 remain open.\n",
      "Before step 4, 35 out of 100 remain open.\n",
      "Before step 5, 31 out of 100 remain open.\n",
      "After step 5, 31 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "97/97 [==============================] - 2s 22ms/step - loss: 0.0659 - value_output_loss: 0.0422 - reward_output_loss: 0.0118 - reward_confidence_output_loss: 0.0119\n",
      "Epoch 2/3\n",
      "97/97 [==============================] - 2s 22ms/step - loss: 0.0641 - value_output_loss: 0.0402 - reward_output_loss: 0.0119 - reward_confidence_output_loss: 0.0120\n",
      "Epoch 3/3\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 0.0594 - value_output_loss: 0.0364 - reward_output_loss: 0.0115 - reward_confidence_output_loss: 0.0115\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1694 - val_loss: 0.1617\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1485 - val_loss: 0.1555\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1394 - val_loss: 0.1545\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1328 - val_loss: 0.1539\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1276 - val_loss: 0.1532\n",
      "Round 12.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 90 out of 100 remain open.\n",
      "Before step 3, 79 out of 100 remain open.\n",
      "Before step 4, 37 out of 100 remain open.\n",
      "Before step 5, 33 out of 100 remain open.\n",
      "After step 5, 31 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "103/103 [==============================] - 2s 23ms/step - loss: 0.0673 - value_output_loss: 0.0423 - reward_output_loss: 0.0125 - reward_confidence_output_loss: 0.0125\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 2s 23ms/step - loss: 0.0647 - value_output_loss: 0.0396 - reward_output_loss: 0.0125 - reward_confidence_output_loss: 0.0126\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 2s 23ms/step - loss: 0.0613 - value_output_loss: 0.0374 - reward_output_loss: 0.0120 - reward_confidence_output_loss: 0.0120\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1581 - val_loss: 0.1457\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1381 - val_loss: 0.1398\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1297 - val_loss: 0.1382\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1240 - val_loss: 0.1374\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1190 - val_loss: 0.1367\n",
      "Round 13.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 89 out of 100 remain open.\n",
      "Before step 3, 81 out of 100 remain open.\n",
      "Before step 4, 37 out of 100 remain open.\n",
      "Before step 5, 32 out of 100 remain open.\n",
      "After step 5, 32 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "108/108 [==============================] - 2s 22ms/step - loss: 0.0691 - value_output_loss: 0.0443 - reward_output_loss: 0.0124 - reward_confidence_output_loss: 0.0124\n",
      "Epoch 2/3\n",
      "108/108 [==============================] - 2s 23ms/step - loss: 0.0651 - value_output_loss: 0.0405 - reward_output_loss: 0.0123 - reward_confidence_output_loss: 0.0124\n",
      "Epoch 3/3\n",
      "108/108 [==============================] - 2s 23ms/step - loss: 0.0615 - value_output_loss: 0.0378 - reward_output_loss: 0.0119 - reward_confidence_output_loss: 0.0119\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.1485 - val_loss: 0.1366\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1289 - val_loss: 0.1304\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1214 - val_loss: 0.1315\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1159 - val_loss: 0.1308\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1114 - val_loss: 0.1315\n",
      "Round 14.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 88 out of 100 remain open.\n",
      "Before step 3, 80 out of 100 remain open.\n",
      "Before step 4, 44 out of 100 remain open.\n",
      "Before step 5, 38 out of 100 remain open.\n",
      "After step 5, 37 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "114/114 [==============================] - 3s 22ms/step - loss: 0.0675 - value_output_loss: 0.0425 - reward_output_loss: 0.0125 - reward_confidence_output_loss: 0.0125\n",
      "Epoch 2/3\n",
      "114/114 [==============================] - 3s 22ms/step - loss: 0.0635 - value_output_loss: 0.0390 - reward_output_loss: 0.0122 - reward_confidence_output_loss: 0.0122\n",
      "Epoch 3/3\n",
      "114/114 [==============================] - 3s 23ms/step - loss: 0.0590 - value_output_loss: 0.0356 - reward_output_loss: 0.0117 - reward_confidence_output_loss: 0.0117\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1401 - val_loss: 0.1259\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.1220 - val_loss: 0.1215\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.1138 - val_loss: 0.1206\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.1086 - val_loss: 0.1208\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1048 - val_loss: 0.1231\n",
      "Round 15.\n",
      "Before step 1, 100 out of 100 remain open.\n",
      "Before step 2, 91 out of 100 remain open.\n",
      "Before step 3, 79 out of 100 remain open.\n",
      "Before step 4, 48 out of 100 remain open.\n",
      "Before step 5, 36 out of 100 remain open.\n",
      "After step 5, 35 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "119/119 [==============================] - 3s 22ms/step - loss: 0.0638 - value_output_loss: 0.0396 - reward_output_loss: 0.0121 - reward_confidence_output_loss: 0.0121\n",
      "Epoch 2/3\n",
      "119/119 [==============================] - 3s 22ms/step - loss: 0.0634 - value_output_loss: 0.0399 - reward_output_loss: 0.0118 - reward_confidence_output_loss: 0.0118\n",
      "Epoch 3/3\n",
      "119/119 [==============================] - 3s 23ms/step - loss: 0.0609 - value_output_loss: 0.0374 - reward_output_loss: 0.0118 - reward_confidence_output_loss: 0.0118\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1333 - val_loss: 0.1179\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1154 - val_loss: 0.1148\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.1075 - val_loss: 0.1140\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.1032 - val_loss: 0.1136\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0992 - val_loss: 0.1148\n",
      "Round 16.\n",
      "Before step 1, 98 out of 100 remain open.\n",
      "Before step 2, 83 out of 100 remain open.\n",
      "Before step 3, 71 out of 100 remain open.\n",
      "Before step 4, 29 out of 100 remain open.\n",
      "Before step 5, 25 out of 100 remain open.\n",
      "After step 5, 21 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.0650 - value_output_loss: 0.0405 - reward_output_loss: 0.0122 - reward_confidence_output_loss: 0.0122\n",
      "Epoch 2/3\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.0636 - value_output_loss: 0.0395 - reward_output_loss: 0.0121 - reward_confidence_output_loss: 0.0121\n",
      "Epoch 3/3\n",
      "124/124 [==============================] - 3s 25ms/step - loss: 0.0580 - value_output_loss: 0.0351 - reward_output_loss: 0.0115 - reward_confidence_output_loss: 0.0115\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1311 - val_loss: 0.1183\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1129 - val_loss: 0.1142\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1059 - val_loss: 0.1138\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1013 - val_loss: 0.1157\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0968 - val_loss: 0.1150\n",
      "Round 17.\n",
      "Before step 1, 100 out of 100 remain open.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [29], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_problems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs_per_episode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m     10\u001b[0m         _, states \u001b[38;5;241m=\u001b[39m rubiks\u001b[38;5;241m.\u001b[39mtask_action(states,rng\u001b[38;5;241m.\u001b[39mchoice(a\u001b[38;5;241m=\u001b[39mtask\u001b[38;5;241m.\u001b[39mn_actions,size\u001b[38;5;241m=\u001b[39mn))\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\classroom.py:43\u001b[0m, in \u001b[0;36mclassroom.run_training_batch\u001b[1;34m(self, n_problems, epochs_per_episode)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_training_batch\u001b[39m(\u001b[39mself\u001b[39m, n_problems, epochs_per_episode):\n\u001b[0;32m     42\u001b[0m     problems \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mteacher\u001b[39m.\u001b[39mgenerate_problems(n_problems)\n\u001b[1;32m---> 43\u001b[0m     replay_record, proof_nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_students(problems)\n\u001b[0;32m     45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m n_problems\n\u001b[0;32m     46\u001b[0m     inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\classroom.py:108\u001b[0m, in \u001b[0;36mclassroom.test_students\u001b[1;34m(self, start_states)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBefore step \u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(unfinished_task_indices)\u001b[39m}\u001b[39;00m\u001b[39m out of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(task_nodes)\u001b[39m}\u001b[39;00m\u001b[39m remain open.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 108\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstudent\u001b[39m.\u001b[39;49mrun_action_step([task_nodes[i] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m unfinished_task_indices])\n\u001b[0;32m    110\u001b[0m \u001b[39mfor\u001b[39;00m j, (action, pi, eval_root) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(result):\n\u001b[0;32m    112\u001b[0m     k \u001b[39m=\u001b[39m unfinished_task_indices[j]\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:70\u001b[0m, in \u001b[0;36mstudent.run_action_step\u001b[1;34m(self, task_nodes)\u001b[0m\n\u001b[0;32m     66\u001b[0m eval_trees \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(initial_eval_trees)\n\u001b[0;32m     68\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_sim):\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_simulation_step(eval_trees)\n\u001b[0;32m     71\u001b[0m     eval_trees\u001b[39m.\u001b[39mdifference_update([e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m eval_trees \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39mcompleted])\n\u001b[0;32m     73\u001b[0m result_list \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:46\u001b[0m, in \u001b[0;36mstudent.run_simulation_step\u001b[1;34m(self, eval_trees)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m eval_trees:\n\u001b[0;32m     44\u001b[0m     eval_leaves\u001b[39m.\u001b[39mappend(t\u001b[39m.\u001b[39mfind_leaf())\n\u001b[1;32m---> 46\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpand_task_nodes(eval_leaves)\n\u001b[0;32m     48\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(eval_trees):\n\u001b[0;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mcompleted:\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:31\u001b[0m, in \u001b[0;36mstudent.expand_task_nodes\u001b[1;34m(self, task_nodes)\u001b[0m\n\u001b[0;32m     28\u001b[0m states \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([t\u001b[39m.\u001b[39mstate \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m task_nodes],dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[0;32m     29\u001b[0m state_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\u001b[39m.\u001b[39mmake_input(states)\n\u001b[1;32m---> 31\u001b[0m \u001b[39meval\u001b[39m,reward,reward_confidence \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mneural_network\u001b[39m.\u001b[39;49mpredict_value(state_input)\n\u001b[0;32m     33\u001b[0m t:task_tree_node\n\u001b[0;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(task_nodes):\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\general_task_network.py:147\u001b[0m, in \u001b[0;36mstudent_network.predict_value\u001b[1;34m(self, input_state)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_value\u001b[39m(\u001b[39mself\u001b[39m, input_state):\n\u001b[1;32m--> 147\u001b[0m     value, reward, reward_confidence \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue_network(input_state)\n\u001b[0;32m    148\u001b[0m     value, reward, reward_confidence \u001b[39m=\u001b[39m (value\u001b[39m.\u001b[39mnumpy(),reward\u001b[39m.\u001b[39mnumpy(),reward_confidence\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m    150\u001b[0m     \u001b[39mreturn\u001b[39;00m value, reward, reward_confidence\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:590\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    588\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 590\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1148\u001b[0m ):\n\u001b[1;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py:515\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \n\u001b[0;32m    500\u001b[0m \u001b[39m    In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[39m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 515\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py:672\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    671\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 672\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mlayer(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    674\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[0;32m    676\u001b[0m     node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)\n\u001b[0;32m    677\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1148\u001b[0m ):\n\u001b[1;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:241\u001b[0m, in \u001b[0;36mDense.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    237\u001b[0m         outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39membedding_lookup_sparse(\n\u001b[0;32m    238\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel, ids, weights, combiner\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msum\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m         )\n\u001b[0;32m    240\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 241\u001b[0m         outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mmatmul(a\u001b[39m=\u001b[39;49minputs, b\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel)\n\u001b[0;32m    242\u001b[0m \u001b[39m# Broadcast kernel to inputs.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mtensordot(inputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel, [[rank \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m], [\u001b[39m0\u001b[39m]])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    141\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ops\u001b[39m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m op(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m   bound_arguments \u001b[39m=\u001b[39m signature\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    144\u001b[0m   bound_arguments\u001b[39m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3842\u001b[0m, in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[0;32m   3839\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39mbatch_mat_mul_v3(\n\u001b[0;32m   3840\u001b[0m       a, b, adj_x\u001b[39m=\u001b[39madjoint_a, adj_y\u001b[39m=\u001b[39madjoint_b, Tout\u001b[39m=\u001b[39moutput_type, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m   3841\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3842\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mmat_mul(\n\u001b[0;32m   3843\u001b[0m       a, b, transpose_a\u001b[39m=\u001b[39;49mtranspose_a, transpose_b\u001b[39m=\u001b[39;49mtranspose_b, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6171\u001b[0m, in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6169\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   6170\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 6171\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   6172\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMatMul\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, a, b, \u001b[39m\"\u001b[39;49m\u001b[39mtranspose_a\u001b[39;49m\u001b[39m\"\u001b[39;49m, transpose_a, \u001b[39m\"\u001b[39;49m\u001b[39mtranspose_b\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   6173\u001b[0m       transpose_b)\n\u001b[0;32m   6174\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   6175\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n=8192\n",
    "rng = np.random.default_rng(seed=0)\n",
    "states = np.arange(task.state_size)[None,:].repeat(n,axis=0)\n",
    "\n",
    "for k in range(20):\n",
    "    print(f\"Round {k}.\")\n",
    "    c.run_training_batch(n_problems=100,epochs_per_episode=3)\n",
    "\n",
    "    for i in range(50):\n",
    "        _, states = rubiks.task_action(states,rng.choice(a=task.n_actions,size=n))\n",
    "\n",
    "    actions = rng.choice(a=task.n_actions,size=n)\n",
    "    _, next_states = rubiks.task_action(states,actions)\n",
    "\n",
    "    actions = (np.arange(task.n_actions) == actions[...,None]).astype(float)\n",
    "    colors = rubiks.make_neural_input(states)\n",
    "    next_colors = rubiks.make_neural_input(next_states)\n",
    "    my_student_network.fit_state(colors,actions,next_colors,epochs = 5)\n",
    "\n",
    "    #if k % 10 == 9:\n",
    "    #  my_student_network.save(\"models/combined/trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 2, 4, 0, 2, 0, 2, 5, 4, 1, 4, 4, 1, 0, 3, 4, 0, 3, 0, 3, 5, 2,\n",
       "         4, 2, 2, 5, 1, 0, 3, 4, 3, 3, 5, 1, 2, 4, 1, 2, 1, 2, 5, 5, 1, 5,\n",
       "         5, 0, 1, 3, 4, 1, 3, 1, 3, 5]], dtype=int64),\n",
       " array([0, 2, 4, 0, 2, 0, 2, 5, 4, 1, 4, 4, 0, 0, 3, 4, 0, 3, 0, 3, 5, 2,\n",
       "        4, 2, 2, 5, 1, 0, 3, 4, 3, 3, 5, 1, 2, 4, 1, 2, 1, 2, 5, 5, 1, 5,\n",
       "        5, 0, 1, 3, 4, 1, 3, 1, 3, 5]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states =  np.arange(54,dtype=int)[None,:]\n",
    "actions = np.array([9],dtype=int)\n",
    "prediction = my_student_network.predict_state(task.make_input(states),(np.arange(task.n_actions) == actions[...,None]).astype(float))\n",
    "prediction.reshape(1,54,6).argmax(axis=2), rubiks.start_coloring[rubiks.task_action(states,actions)[1][0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea0df938a2fb4e996541c96a685bf803a61ab029232d990df5cc8c7e24c9f388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
