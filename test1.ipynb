{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run in colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/Github/Taskmaster\n",
    "#!pip install tensorflow --upgrade\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import small_rubiks as rubiks\n",
    "import numpy as np\n",
    "from student import student\n",
    "from classroom import classroom\n",
    "from teacher import teacher\n",
    "from small_rubiks_neural_networks import student_network\n",
    "from utils import dotdict\n",
    "from keras import regularizers\n",
    "\n",
    "task = rubiks.rubiks_task\n",
    "setup = rubiks.rubiks_setup\n",
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "#my_student_network = student_network.load(\"models/trained.h5\")\n",
    "params = dotdict({\n",
    "            \"residual_weights_reg\" : None,\n",
    "            \"residual_bias_reg\" : None,\n",
    "            \"relu_leak\" : 0.1,\n",
    "            \"residual_units\" : 300,\n",
    "            \"learning_rate\" : 0.001,\n",
    "            \"residual_layers\" : 4\n",
    "})\n",
    "my_student_network = student_network.create(params)\n",
    "student_template = student(task, 50,my_student_network)\n",
    "t = teacher(setup, lambda n : 1+rng.poisson(lam=3,size=n))\n",
    "c = classroom(task, setup, t, student_template, n_students=1, max_steps=10, buffer_size = lambda n : 2048)\n",
    "#c.run_training_batch(n_problems=1,epochs_per_episode=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished step 0, 94 out of 100 remain open.\n",
      "Finished step 1, 81 out of 100 remain open.\n",
      "Finished step 2, 76 out of 100 remain open.\n",
      "Finished step 3, 73 out of 100 remain open.\n",
      "Finished step 4, 69 out of 100 remain open.\n",
      "Finished step 5, 69 out of 100 remain open.\n",
      "Finished step 6, 69 out of 100 remain open.\n",
      "Finished step 7, 69 out of 100 remain open.\n",
      "Finished step 8, 69 out of 100 remain open.\n",
      "Finished step 9, 69 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\leove\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\leove\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "47/47 [==============================] - 5s 10ms/step - loss: 0.9560 - eval_output_loss: 0.2725 - policy_output_loss: 0.1384\n",
      "Epoch 2/3\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.3053 - eval_output_loss: 0.0770 - policy_output_loss: 0.0743\n",
      "Epoch 3/3\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1903 - eval_output_loss: 0.0476 - policy_output_loss: 0.0474\n",
      "Finished step 0, 98 out of 100 remain open.\n",
      "Finished step 1, 89 out of 100 remain open.\n",
      "Finished step 2, 81 out of 100 remain open.\n",
      "Finished step 3, 79 out of 100 remain open.\n",
      "Finished step 4, 75 out of 100 remain open.\n",
      "Finished step 5, 75 out of 100 remain open.\n",
      "Finished step 6, 75 out of 100 remain open.\n",
      "Finished step 7, 75 out of 100 remain open.\n",
      "Finished step 8, 75 out of 100 remain open.\n",
      "Finished step 9, 75 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.2022 - eval_output_loss: 0.0532 - policy_output_loss: 0.0426\n",
      "Epoch 2/3\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1719 - eval_output_loss: 0.0465 - policy_output_loss: 0.0324\n",
      "Epoch 3/3\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1467 - eval_output_loss: 0.0394 - policy_output_loss: 0.0286\n",
      "Finished step 0, 93 out of 100 remain open.\n",
      "Finished step 1, 84 out of 100 remain open.\n",
      "Finished step 2, 69 out of 100 remain open.\n",
      "Finished step 3, 67 out of 100 remain open.\n",
      "Finished step 4, 64 out of 100 remain open.\n",
      "Finished step 5, 62 out of 100 remain open.\n",
      "Finished step 6, 61 out of 100 remain open.\n",
      "Finished step 7, 61 out of 100 remain open.\n",
      "Finished step 8, 61 out of 100 remain open.\n",
      "Finished step 9, 61 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.2315 - eval_output_loss: 0.0689 - policy_output_loss: 0.0247\n",
      "Epoch 2/3\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.2330 - eval_output_loss: 0.0700 - policy_output_loss: 0.0230\n",
      "Epoch 3/3\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2351 - eval_output_loss: 0.0712 - policy_output_loss: 0.0215\n",
      "Finished step 0, 95 out of 100 remain open.\n",
      "Finished step 1, 78 out of 100 remain open.\n",
      "Finished step 2, 57 out of 100 remain open.\n",
      "Finished step 3, 50 out of 100 remain open.\n",
      "Finished step 4, 48 out of 100 remain open.\n",
      "Finished step 5, 45 out of 100 remain open.\n",
      "Finished step 6, 45 out of 100 remain open.\n",
      "Finished step 7, 45 out of 100 remain open.\n",
      "Finished step 8, 45 out of 100 remain open.\n",
      "Finished step 9, 45 out of 100 remain open.\n",
      "Epoch 1/3\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2833 - eval_output_loss: 0.0907 - policy_output_loss: 0.0113\n",
      "Epoch 2/3\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2931 - eval_output_loss: 0.0940 - policy_output_loss: 0.0112\n",
      "Epoch 3/3\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2815 - eval_output_loss: 0.0902 - policy_output_loss: 0.0109\n",
      "Finished step 0, 93 out of 100 remain open.\n",
      "Finished step 1, 83 out of 100 remain open.\n",
      "Finished step 2, 60 out of 100 remain open.\n",
      "Finished step 3, 52 out of 100 remain open.\n",
      "Finished step 4, 50 out of 100 remain open.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_problems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs_per_episode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#if i % 10 == 0:\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m#    my_student_network.save(\"models/trained.h5\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\classroom.py:43\u001b[0m, in \u001b[0;36mclassroom.run_training_batch\u001b[1;34m(self, n_problems, epochs_per_episode)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_training_batch\u001b[39m(\u001b[39mself\u001b[39m, n_problems, epochs_per_episode):\n\u001b[0;32m     42\u001b[0m     problems \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mteacher\u001b[39m.\u001b[39mgenerate_problems(n_problems)\n\u001b[1;32m---> 43\u001b[0m     replay_record, proof_nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_students(problems)\n\u001b[0;32m     45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m n_problems\n\u001b[0;32m     46\u001b[0m     inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\classroom.py:93\u001b[0m, in \u001b[0;36mclassroom.test_students\u001b[1;34m(self, start_states)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_steps):\n\u001b[0;32m     92\u001b[0m     unfinished_task_indices \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i,p \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(task_nodes) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m p\u001b[39m.\u001b[39mcompleted]\n\u001b[1;32m---> 93\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstudent\u001b[39m.\u001b[39;49mrun_action_step([task_nodes[i] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m unfinished_task_indices])\n\u001b[0;32m     95\u001b[0m     \u001b[39mfor\u001b[39;00m j, (action, pi, eval_root) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(result):\n\u001b[0;32m     97\u001b[0m         k \u001b[39m=\u001b[39m unfinished_task_indices[j]\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:61\u001b[0m, in \u001b[0;36mstudent.run_action_step\u001b[1;34m(self, task_nodes)\u001b[0m\n\u001b[0;32m     57\u001b[0m eval_trees \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(initial_eval_trees)\n\u001b[0;32m     59\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_sim):\n\u001b[1;32m---> 61\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_simulation_step(eval_trees)\n\u001b[0;32m     62\u001b[0m     eval_trees\u001b[39m.\u001b[39mdifference_update([e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m eval_trees \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39mcompleted])\n\u001b[0;32m     64\u001b[0m result_list \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:37\u001b[0m, in \u001b[0;36mstudent.run_simulation_step\u001b[1;34m(self, eval_trees)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m eval_trees:\n\u001b[0;32m     35\u001b[0m     eval_leaves\u001b[39m.\u001b[39mappend(t\u001b[39m.\u001b[39mfind_leaf())\n\u001b[1;32m---> 37\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpand_task_nodes(eval_leaves)\n\u001b[0;32m     39\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(eval_trees):\n\u001b[0;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mcompleted:\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\student.py:23\u001b[0m, in \u001b[0;36mstudent.expand_task_nodes\u001b[1;34m(self, task_nodes)\u001b[0m\n\u001b[0;32m     20\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(task_nodes)\n\u001b[0;32m     21\u001b[0m task_nodes \u001b[39m=\u001b[39m [t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m s \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (t\u001b[39m.\u001b[39mcompleted \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mexpanded)]\n\u001b[1;32m---> 23\u001b[0m \u001b[39meval\u001b[39m,policy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mneural_network\u001b[39m.\u001b[39;49mpredict_value(task_nodes)\n\u001b[0;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(task_nodes):\n\u001b[0;32m     27\u001b[0m     t\u001b[39m.\u001b[39mexpand(\u001b[39meval\u001b[39m[i],policy[i])\n",
      "File \u001b[1;32mc:\\Users\\leove\\OneDrive\\Documents\\Selberprogrammiertes\\Taskmaster\\small_rubiks_neural_networks.py:89\u001b[0m, in \u001b[0;36mstudent_network.predict_value\u001b[1;34m(self, task_nodes)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(task_nodes):\n\u001b[0;32m     87\u001b[0m     nn_input[i] \u001b[39m=\u001b[39m rubiks\u001b[39m.\u001b[39mmake_neural_input(t\u001b[39m.\u001b[39mstate)\n\u001b[1;32m---> 89\u001b[0m \u001b[39meval\u001b[39m, policy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue_network(nn_input)\n\u001b[0;32m     90\u001b[0m \u001b[39meval\u001b[39m, policy \u001b[39m=\u001b[39m (\u001b[39meval\u001b[39m\u001b[39m.\u001b[39mnumpy(),policy\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m     92\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39meval\u001b[39m, policy\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:590\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    588\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 590\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1148\u001b[0m ):\n\u001b[1;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py:515\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \n\u001b[0;32m    500\u001b[0m \u001b[39m    In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[39m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 515\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py:672\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    671\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 672\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mlayer(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    674\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[0;32m    676\u001b[0m     node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)\n\u001b[0;32m    677\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1148\u001b[0m ):\n\u001b[1;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:788\u001b[0m, in \u001b[0;36mBatchNormalizationBase.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[39mif\u001b[39;00m scale \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    787\u001b[0m     scale \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(scale, inputs\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m--> 788\u001b[0m outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mbatch_normalization(\n\u001b[0;32m    789\u001b[0m     inputs,\n\u001b[0;32m    790\u001b[0m     _broadcast(mean),\n\u001b[0;32m    791\u001b[0m     _broadcast(variance),\n\u001b[0;32m    792\u001b[0m     offset,\n\u001b[0;32m    793\u001b[0m     scale,\n\u001b[0;32m    794\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    795\u001b[0m )\n\u001b[0;32m    796\u001b[0m \u001b[39mif\u001b[39;00m inputs_dtype \u001b[39min\u001b[39;00m (tf\u001b[39m.\u001b[39mfloat16, tf\u001b[39m.\u001b[39mbfloat16):\n\u001b[0;32m    797\u001b[0m     outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(outputs, inputs_dtype)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:1482\u001b[0m, in \u001b[0;36mbatch_normalization\u001b[1;34m(x, mean, variance, offset, scale, variance_epsilon, name)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Batch normalization.\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m \n\u001b[0;32m   1431\u001b[0m \u001b[39mNormalizes a tensor by `mean` and `variance`, and applies (optionally) a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1479\u001b[0m \u001b[39m    ([pdf](http://proceedings.mlr.press/v37/ioffe15.pdf))\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(name, \u001b[39m\"\u001b[39m\u001b[39mbatchnorm\u001b[39m\u001b[39m\"\u001b[39m, [x, mean, variance, scale, offset]):\n\u001b[1;32m-> 1482\u001b[0m   inv \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39mrsqrt(variance \u001b[39m+\u001b[39;49m variance_epsilon)\n\u001b[0;32m   1483\u001b[0m   \u001b[39mif\u001b[39;00m scale \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1484\u001b[0m     inv \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m scale\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\variables.py:1013\u001b[0m, in \u001b[0;36mVariable._OverloadOperator.<locals>._run_op\u001b[1;34m(a, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_op\u001b[39m(a, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1012\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1013\u001b[0m   \u001b[39mreturn\u001b[39;00m tensor_oper(a\u001b[39m.\u001b[39mvalue(), \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1478\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1473\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1474\u001b[0m   \u001b[39m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[0;32m   1475\u001b[0m   \u001b[39m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[0;32m   1476\u001b[0m   \u001b[39m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[0;32m   1477\u001b[0m   x, y \u001b[39m=\u001b[39m maybe_promote_tensors(x, y)\n\u001b[1;32m-> 1478\u001b[0m   \u001b[39mreturn\u001b[39;00m func(x, y, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1479\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1480\u001b[0m   \u001b[39m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m   \u001b[39m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1484\u001b[0m   \u001b[39m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[0;32m   1485\u001b[0m   \u001b[39m# informative.\u001b[39;00m\n\u001b[0;32m   1486\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mtype\u001b[39m(y), \u001b[39m\"\u001b[39m\u001b[39m__r\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m op_name):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1871\u001b[0m, in \u001b[0;36m_add_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1869\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39madd(x, y, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m   1870\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1871\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49madd_v2(x, y, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:477\u001b[0m, in \u001b[0;36madd_v2\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m    476\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 477\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m    478\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mAddV2\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, x, y)\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m    480\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    c.run_training_batch(n_problems=100,epochs_per_episode=3)\n",
    "    #if i % 10 == 0:\n",
    "    #    my_student_network.save(\"models/trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "120/120 [==============================] - 3s 6ms/step - loss: 0.6253 - val_loss: 0.4650\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4461 - val_loss: 0.4431\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4259 - val_loss: 0.4346\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.4116 - val_loss: 0.4288\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4003 - val_loss: 0.4252\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3905 - val_loss: 0.4197\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3819 - val_loss: 0.4166\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3740 - val_loss: 0.4122\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3671 - val_loss: 0.4092\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3602 - val_loss: 0.4064\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3987 - val_loss: 0.4006\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3767 - val_loss: 0.3878\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3653 - val_loss: 0.3826\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3558 - val_loss: 0.3790\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3481 - val_loss: 0.3750\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3405 - val_loss: 0.3709\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3340 - val_loss: 0.3676\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3277 - val_loss: 0.3636\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3213 - val_loss: 0.3614\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3152 - val_loss: 0.3574\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3537 - val_loss: 0.3484\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3311 - val_loss: 0.3381\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3188 - val_loss: 0.3283\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3089 - val_loss: 0.3244\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3001 - val_loss: 0.3186\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2922 - val_loss: 0.3152\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2849 - val_loss: 0.3102\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2776 - val_loss: 0.3076\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2724 - val_loss: 0.3024\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2670 - val_loss: 0.3026\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3035 - val_loss: 0.2988\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2838 - val_loss: 0.2843\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2728 - val_loss: 0.2793\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2654 - val_loss: 0.2744\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2581 - val_loss: 0.2709\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2524 - val_loss: 0.2689\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2468 - val_loss: 0.2657\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2433 - val_loss: 0.2629\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2376 - val_loss: 0.2645\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2340 - val_loss: 0.2600\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2704 - val_loss: 0.2538\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2523 - val_loss: 0.2499\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2436 - val_loss: 0.2419\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2366 - val_loss: 0.2391\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2321 - val_loss: 0.2406\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2272 - val_loss: 0.2368\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2227 - val_loss: 0.2352\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2191 - val_loss: 0.2354\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2154 - val_loss: 0.2329\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2123 - val_loss: 0.2323\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2457 - val_loss: 0.2246\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2293 - val_loss: 0.2184\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2229 - val_loss: 0.2196\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2163 - val_loss: 0.2167\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2122 - val_loss: 0.2169\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2082 - val_loss: 0.2109\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2042 - val_loss: 0.2122\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2001 - val_loss: 0.2115\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1969 - val_loss: 0.2089\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1938 - val_loss: 0.2086\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2281 - val_loss: 0.2047\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2119 - val_loss: 0.2036\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2054 - val_loss: 0.1968\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1996 - val_loss: 0.1958\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1952 - val_loss: 0.1950\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1918 - val_loss: 0.1969\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1878 - val_loss: 0.1943\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1859 - val_loss: 0.1935\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1833 - val_loss: 0.1914\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1799 - val_loss: 0.1902\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.2110 - val_loss: 0.1862\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1961 - val_loss: 0.1815\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1890 - val_loss: 0.1780\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1841 - val_loss: 0.1823\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1798 - val_loss: 0.1815\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1769 - val_loss: 0.1759\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1739 - val_loss: 0.1745\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.1707 - val_loss: 0.1760\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 0.1686 - val_loss: 0.1720\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1669 - val_loss: 0.1735\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1971 - val_loss: 0.1683\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1840 - val_loss: 0.1649\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1774 - val_loss: 0.1648\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1719 - val_loss: 0.1620\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1680 - val_loss: 0.1624\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1650 - val_loss: 0.1597\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1624 - val_loss: 0.1616\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1595 - val_loss: 0.1603\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1573 - val_loss: 0.1593\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1552 - val_loss: 0.1574\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1834 - val_loss: 0.1547\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1693 - val_loss: 0.1497\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1633 - val_loss: 0.1519\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1598 - val_loss: 0.1460\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1566 - val_loss: 0.1447\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1528 - val_loss: 0.1475\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1507 - val_loss: 0.1438\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1484 - val_loss: 0.1421\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1467 - val_loss: 0.1414\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1458 - val_loss: 0.1426\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1712 - val_loss: 0.1440\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1597 - val_loss: 0.1392\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1537 - val_loss: 0.1387\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1487 - val_loss: 0.1370\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1460 - val_loss: 0.1376\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1436 - val_loss: 0.1380\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1406 - val_loss: 0.1333\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1400 - val_loss: 0.1346\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1372 - val_loss: 0.1326\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1346 - val_loss: 0.1340\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1626 - val_loss: 0.1285\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1503 - val_loss: 0.1285\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1435 - val_loss: 0.1210\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1407 - val_loss: 0.1252\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1372 - val_loss: 0.1205\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1350 - val_loss: 0.1190\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1326 - val_loss: 0.1198\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1313 - val_loss: 0.1201\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1288 - val_loss: 0.1190\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1282 - val_loss: 0.1152\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.1529 - val_loss: 0.1169\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1422 - val_loss: 0.1164\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1371 - val_loss: 0.1129\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1308 - val_loss: 0.1118\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1293 - val_loss: 0.1104\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1280 - val_loss: 0.1148\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1253 - val_loss: 0.1111\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1233 - val_loss: 0.1096\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1212 - val_loss: 0.1074\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.1203 - val_loss: 0.1158\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.1430 - val_loss: 0.1139\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1327 - val_loss: 0.1033\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1273 - val_loss: 0.1020\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1244 - val_loss: 0.1000\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1209 - val_loss: 0.1036\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1190 - val_loss: 0.0984\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1171 - val_loss: 0.0996\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.1153 - val_loss: 0.0989\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1141 - val_loss: 0.1005\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1129 - val_loss: 0.1021\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1373 - val_loss: 0.0959\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1263 - val_loss: 0.0915\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1206 - val_loss: 0.0898\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1185 - val_loss: 0.0931\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1179 - val_loss: 0.0919\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1128 - val_loss: 0.0910\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1122 - val_loss: 0.0892\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1103 - val_loss: 0.0894\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1083 - val_loss: 0.0886\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1079 - val_loss: 0.0907\n"
     ]
    }
   ],
   "source": [
    "from small_rubiks_neural_networks import student_network\n",
    "import numpy as np\n",
    "import small_rubiks as rubiks\n",
    "from utils import dotdict\n",
    "from keras import regularizers\n",
    "\n",
    "params = dotdict({\n",
    "    \"residual_weights_reg\" : regularizers.l2(0),\n",
    "    \"residual_bias_reg\" : regularizers.l2(0),\n",
    "    \"relu_leak\" : 0.1,\n",
    "    \"residual_units\" : 100,\n",
    "    \"learning_rate\" : 0.001,\n",
    "    \"residual_layers\" : 4\n",
    "})\n",
    "\n",
    "my_student_network = student_network()\n",
    "my_student_network.build_state_network(params)\n",
    "\n",
    "n=4096\n",
    "rng = np.random.default_rng(seed=0)\n",
    "states = np.arange(24)[None,:].repeat(n,axis=0)\n",
    "\n",
    "for k in range(15):\n",
    "    for i in range(30):\n",
    "        _, states = rubiks.task_action(states,rng.choice(a=12,size=n))\n",
    "\n",
    "    actions = rng.choice(12,size=n)\n",
    "    _, next_states = rubiks.task_action(states,actions)\n",
    "    my_student_network.fit_state(states,actions,next_states,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.arange(24)[None,:]\n",
    "actions = np.array([0])\n",
    "prediction = my_student_network.predict_state(states,actions)\n",
    "prediction.reshape(1,24,6), prediction.reshape(1,24,6).argmax(axis=2), rubiks.start_coloring[rubiks.task_action(states,actions)[1][0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea0df938a2fb4e996541c96a685bf803a61ab029232d990df5cc8c7e24c9f388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
